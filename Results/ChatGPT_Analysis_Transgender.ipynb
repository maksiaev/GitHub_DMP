{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c580c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Alexander Maksiaev\n",
    "# Citation: https://medium.com/the-data-perspectives/workarounds-openai-models-token-limit-issues-3ea52a60d937\n",
    "# Purpose: Have ChatGPT do sentiment analysis on the autism textbooks using the \"map reduce\" technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ddb9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping\n",
    "\n",
    "import os\n",
    "import docx\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import re\n",
    "# from langchain_openai import OpenAI\n",
    "# from langchain.chains.question_answering import load_qa_chain\n",
    "# # from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.docstore.document import Document\n",
    "# import docx2txt\n",
    "# from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "key = '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' # yourapi key here\n",
    "\n",
    "client = OpenAI(api_key = key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66478ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch into textbook directory\n",
    "os.getcwd()\n",
    "\n",
    "textbook_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\Textbook_Dump_Transgender\"\n",
    "\n",
    "textbooks = os.listdir(textbook_dir)\n",
    "\n",
    "# Go back to textbook directory \n",
    "\n",
    "os.chdir(textbook_dir)\n",
    "\n",
    "# Function to get full text\n",
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return fullText\n",
    "\n",
    "# Dictionary filled with text for all the books, minus the titles\n",
    "title_text = {}\n",
    "for book in textbooks:\n",
    "    total_text = getText(book)\n",
    "    text_without_title = total_text[4:]\n",
    "    for piece in text_without_title:\n",
    "        if piece == '':\n",
    "            text_without_title.remove(piece) # Does not get rid of all whitespace, but ah well.\n",
    "    # Make it a list\n",
    "#     text_without_title = list(text_without_title)\n",
    "    title_text[book] = text_without_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f7e20a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p. 391: Treatment guidelines developed by the American Psychiatric Association for gender nonconformity in youth simply outline the options available (Byne et al., 2012). The first option would be to work with the child and caregivers to lessen gender dyspho-ria and decrease cross-gender behaviors and identification on the assumption that these behaviors are unlikely to persist anyway and the negative consequences of social rejection could be avoided, and that avoiding later intrusive surgery would be desirable. A second approach could be described as \"watchful waiting\" by let-ting expressed gender unfold naturally. This goal requires strong support from caregivers and the community because of the poten-tial social and interpersonal risks and lack of integration with peer groups. Yet a third approach advocates actively affirming and encouraging cross-gender identification, but critics point out that gender nonconformity usually does not persist and that taking this course would increase the likelihood of persistence. There is very little hard scientific information on which course would be the most beneficial for a given child. \n"
     ]
    }
   ],
   "source": [
    "print(title_text[\"Abn_Barlow_07_Transgender_v2.docx\"][0])\n",
    "\n",
    "test_text = title_text[\"Abn_Barlow_07_Transgender_v2.docx\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0240e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = load_qa_chain(\n",
    "#     llm, chain_type=\"map_reduce\", verbose=True, return_intermediate_steps=True\n",
    "# )\n",
    "# query = \"For every piece of text I send from now on, give a single sentiment 'score' between -4 and 4 for the following piece of text. -4 represents the most negative sentiment, while 4 represents the most positive sentiment. Give the score as a decimal with up to five significant figures.\"\n",
    "\n",
    "# result = chain({\"input_documents\": text, \"question\": query}\n",
    "# , return_only_outputs=True\n",
    "# )\n",
    "# print(result['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca502eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88243\n"
     ]
    }
   ],
   "source": [
    "# Test to see if it works on one piece of the text\n",
    "\n",
    "\n",
    "\n",
    "query = \"For every piece of text I send from now on, give a single sentiment 'score' between -4 and 4 for the following piece of text. -4 represents the most negative sentiment, while 4 represents the most positive sentiment. Give the score as a decimal with up to five significant figures.\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": query}]\n",
    "messages.append({\"role\":\"user\", \"content\": test_text})\n",
    "\n",
    "answers = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = messages\n",
    ")\n",
    "\n",
    "print(answers.choices[0].message.content)\n",
    "\n",
    "\n",
    "# Test\n",
    "# answers = client.chat.completions.create(\n",
    "#     messages=[{\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"Say this is a test\",\n",
    "#     }],\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69e43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a33f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test to see if it works on the entire textbook\n",
    "# to_append_to_messages = []\n",
    "# for i in range(len(title_text[\"Abn_Barlow_07_Autism.docx\"])):\n",
    "#     to_append_to_messages.append(title_text[\"Abn_Barlow_05_Autism_v2.docx\"][i])\n",
    "    \n",
    "test_query = \"For every piece of text I send from now on, give a single sentiment 'score' between -4 and 4 for the following piece of text. -4 represents the most negative sentiment, while 4 represents the most positive sentiment. Give the score as a decimal with up to five significant figures. Do not give any other text except for the score.\"\n",
    "\n",
    "def one_textbook(textbook_appendage, query):\n",
    "    answers = []\n",
    "    for to_append in textbook_appendage:\n",
    "        messages = [{\"role\": \"user\", \"content\": query}]\n",
    "        messages.append({\"role\":\"user\", \"content\": to_append})\n",
    "\n",
    "        answer = client.chat.completions.create(\n",
    "                model = \"gpt-3.5-turbo\",\n",
    "                messages = messages\n",
    "        )\n",
    "\n",
    "        answers.append(answer.choices[0].message.content)\n",
    "        \n",
    "    total_textbook_sentiment = 0\n",
    "    extra = 0 # If there are extra sentiments hiding, make sure the average isn't off\n",
    "    for sentiment in answers:\n",
    "        sentiment = re.findall(r\"[-+]?(?:\\d*\\.*\\d+)\", sentiment)\n",
    "        if len(sentiment) > 0: # If gpt gave a score\n",
    "            for s in sentiment:\n",
    "                s = float(s)\n",
    "                total_textbook_sentiment += s # Add them all up\n",
    "        if len(sentiment) > 1:\n",
    "            extra += len(sentiment) - 1\n",
    "    total_textbook_sentiment = total_textbook_sentiment/(len(answers) + extra) # Average the sentiments\n",
    "        \n",
    "    return total_textbook_sentiment\n",
    "\n",
    "# test_answers = one_textbook(to_append_to_messages, test_query)\n",
    "\n",
    "# print(test_answers)\n",
    "\n",
    "\n",
    "    \n",
    "# print(total_textbook_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc3acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3413535294117647\n"
     ]
    }
   ],
   "source": [
    "# Another test\n",
    "\n",
    "to_append_to_messages_test = []\n",
    "for i in range(len(title_text[\"Abn_Barlow_05_Transgender_v2.docx\"])):\n",
    "    to_append_to_messages_test.append(title_text[\"Abn_Barlow_05_Transgender_v2.docx\"][i])\n",
    "    \n",
    "print(one_textbook(to_append_to_messages_test, test_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf012158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do all of the textbooks\n",
    "\n",
    "def all_textbooks(textbook_dict, query):\n",
    "    sentiments = {}\n",
    "    for textbook in textbook_dict:\n",
    "        print(\"textbook: \", textbook)\n",
    "        to_append_to_messages = []\n",
    "        for i in range(len(textbook_dict[textbook])):\n",
    "#             print(\"thing: \", i)\n",
    "            to_append_to_messages.append(textbook_dict[textbook][i])\n",
    "        sentiment = one_textbook(to_append_to_messages, query)\n",
    "        sentiments[textbook] = sentiment\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0398e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textbook:  Abn_Barlow_04_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_05_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_06_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_07_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_08_Transgender.docx\n",
      "textbook:  Abn_Brown_05_Transgender.docx\n",
      "textbook:  Abn_Comer_05_Transgender_v2.docx\n",
      "textbook:  Abn_Comer_06_Transgender.docx\n",
      "textbook:  Abn_Comer_07_Transgender.docx\n",
      "textbook:  Abn_Comer_08_Transgender_v2.docx\n",
      "textbook:  Abn_Comer_09_Transgender.docx\n",
      "textbook:  Abn_Hooley_13_Transgender.docx\n",
      "textbook:  Abn_Hooley_14_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_15_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_16_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_17_Transgender.docx\n",
      "textbook:  Abn_Kearney_06_Transgender.docx\n",
      "textbook:  Abn_Mash_02_Transgender.docx\n",
      "textbook:  Abn_Mash_05_Transgender.docx\n",
      "textbook:  Abn_Mash_06_Transgender.docx\n",
      "textbook:  Abn_Nevid_08_Transgender_v2.docx\n",
      "textbook:  Abn_Nevid_09_Transgender.docx\n",
      "textbook:  Abn_Nevid_10_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_03_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_04_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_05_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_06_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_07_Transgender.docx\n",
      "textbook:  Abn_Sue_07_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_08_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_09_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_10_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_11_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_04_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_05_Transgender_v2.docx\n",
      "textbook:  Abn_Whitbourne_06_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_07_Transgender_v2.docx\n",
      "textbook:  Abn_Whitbourne_08_Transgender.docx\n",
      "textbook:  Devo_Berger_05_Transgender.docx\n",
      "textbook:  Devo_Berger_06_Transgender.docx\n",
      "textbook:  Devo_Berger_07_Transgender.docx\n",
      "textbook:  Devo_Berger_08_Transgender.docx\n",
      "textbook:  Devo_Berger_09_Transgender.docx\n",
      "textbook:  Devo_Berger_10_Transgender.docx\n",
      "textbook:  Devo_Berk_08_Transgender.docx\n",
      "textbook:  Devo_Bornstein_02_Transgender.docx\n",
      "textbook:  Devo_Bornstein_04_Transgender_v2.docx\n",
      "textbook:  Devo_Bornstein_05_Transgender_v2.docx\n",
      "textbook:  Devo_Bornstein_07_Transgender.docx\n",
      "textbook:  Devo_Feldman_03_Transgender.docx\n",
      "textbook:  Devo_Feldman_04_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_05_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_06_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_07_Transgender.docx\n",
      "textbook:  Devo_Feldman_08_Transgender.docx\n",
      "textbook:  Devo_Gonzalez-Mena_10_Transgender.docx\n",
      "textbook:  Devo_Gonzalez-Mena_11_Transgender.docx\n",
      "textbook:  Devo_Kail_02_Transgender.docx\n",
      "textbook:  Devo_Kail_05_Transgender.docx\n",
      "textbook:  Devo_Kail_06_Transgender.docx\n",
      "textbook:  Devo_Kail_07_Transgender.docx\n",
      "textbook:  Devo_Miller_06_Transgender.docx\n",
      "textbook:  Devo_Newman_08_Transgender.docx\n",
      "textbook:  Devo_Newman_09_Transgender.docx\n",
      "textbook:  Devo_Newman_10_Transgender_v2.docx\n",
      "textbook:  Devo_Newman_11_Transgender.docx\n",
      "textbook:  Devo_Newman_12_Transgender.docx\n",
      "textbook:  Devo_Newman_13_Transgender.docx\n",
      "textbook:  Devo_Santrock_11_Transgender.docx\n",
      "textbook:  Devo_Santrock_12_Transgender.docx\n",
      "textbook:  Devo_Santrock_13_Transgender.docx\n",
      "textbook:  Devo_Santrock_14_Transgender.docx\n",
      "textbook:  Devo_Santrock_15_Transgender_V2.docx\n",
      "textbook:  Devo_Santrock_16_Transgender.docx\n",
      "textbook:  Devo_Sigelman_05_Transgender.docx\n",
      "textbook:  Devo_Sigelman_07_Transgender.docx\n",
      "textbook:  Devo_Sigelman_08_Transgender.docx\n",
      "textbook:  Devo_Sigelman_09_Transgender.docx\n",
      "textbook:  GS_Andersen_07_Transgender_v2.docx\n",
      "textbook:  GS_Andersen_08_Transgender_v2.docx\n",
      "textbook:  GS_Andersen_09_Transgender.docx\n",
      "textbook:  GS_Brannon_05_Transgender_v2.docx\n",
      "textbook:  GS_Brannon_06_Transgender.docx\n",
      "textbook:  GS_Brannon_07_Transgender.docx\n",
      "textbook:  GS_Healey_03_Transgender_v2.docx\n",
      "textbook:  GS_Healey_04_Transgender.docx\n",
      "textbook:  GS_Healey_05_Transgender.docx\n",
      "textbook:  GS_Helgeson_03_Transgender_v2.docx\n",
      "textbook:  GS_Helgeson_04_Transgender_v2.docx\n",
      "textbook:  GS_Helgeson_05_Transgender.docx\n",
      "textbook:  GS_Kimmel_04_Transgender_v2.docx\n",
      "textbook:  GS_Kimmel_05_Transgender_v2.docx\n",
      "textbook:  GS_Kimmel_06_Transgender.docx\n",
      "textbook:  GS_Newman_01_Transgender_v2.docx\n",
      "textbook:  GS_Newman_02_Transgender_v2.docx\n",
      "textbook:  GS_Newman_03_Transgender.docx\n",
      "textbook:  GS_Robinson_02_Transgender.docx\n",
      "textbook:  GS_Robinson_03_Transgender_v2.docx\n",
      "textbook:  GS_Robinson_04_Transgender.docx\n",
      "textbook:  GS_Rothenberg_08_Transgender_v2.docx\n",
      "textbook:  GS_Rothenberg_09_Transgender_v2.docx\n",
      "textbook:  GS_Rothenberg_10_Transgender.docx\n",
      "textbook:  GS_Wood_10_Transgender_v2.docx\n",
      "textbook:  GS_Wood_11_Transgender_v2.docx\n",
      "textbook:  GS_Wood_12_Transgender.docx\n",
      "textbook:  HS_Carroll_03_Transgender.docx\n",
      "textbook:  HS_Carroll_04_Transgender.docx\n",
      "textbook:  HS_Carroll_05_Transgender.docx\n",
      "textbook:  HS_Crooks_11_Transgender.docx\n",
      "textbook:  HS_Crooks_12_Transgender_v2.docx\n",
      "textbook:  HS_Crooks_13_Transgender.docx\n",
      "textbook:  HS_Greenberg_04_Transgender.docx\n",
      "textbook:  HS_Greenberg_05_Transgender_v2.docx\n",
      "textbook:  HS_Greenberg_06_Transgender.docx\n",
      "textbook:  HS_Hock_02_Transgender.docx\n",
      "textbook:  HS_Hock_03_Transgender.docx\n",
      "textbook:  HS_Hock_04_Transgender.docx\n",
      "textbook:  HS_Hyde_11_Transgender_v2.docx\n",
      "textbook:  HS_Hyde_12_Transgender_v2.docx\n",
      "textbook:  HS_Hyde_13_Transgender.docx\n",
      "textbook:  HS_LeVay_01_Transgender.docx\n",
      "textbook:  HS_LeVay_02_Transgender.docx\n",
      "textbook:  HS_LeVay_03_Transgender.docx\n",
      "textbook:  HS_Yarber_07_Transgender.docx\n",
      "textbook:  HS_Yarber_08_Transgender.docx\n",
      "textbook:  HS_Yarber_09_Transgender.docx\n",
      "textbook:  Intro_Bernstein_06_Transgender.docx\n",
      "textbook:  Intro_Bernstein_07_Transgender_v2.docx\n",
      "textbook:  Intro_Bernstein_08_Transgender.docx\n",
      "textbook:  Intro_Bernstein_09_Transgender_v2.docx\n",
      "textbook:  Intro_Bernstein_10_Transgender.docx\n",
      "textbook:  Intro_Coon_10_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_11_Transgender.docx\n",
      "textbook:  Intro_Coon_12_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_13_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_14_Transgender.docx\n",
      "textbook:  Intro_Griggs_01_Transgender.docx\n",
      "textbook:  Intro_Griggs_04_Transgender.docx\n",
      "textbook:  Intro_Griggs_05_Transgender.docx\n",
      "textbook:  Intro_Kalat_08_Transgender.docx\n",
      "textbook:  Intro_Kalat_11_Transgender.docx\n",
      "textbook:  Intro_Morris_07_Transgender_v2.docx\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-kRjsegsmHRFN0vGELEEXRooK on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_sentiments \u001b[38;5;241m=\u001b[39m all_textbooks(title_text, test_query)\n",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mall_textbooks\u001b[1;34m(textbook_dict, query)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(textbook_dict[textbook])):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#             print(\"thing: \", i)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m             to_append_to_messages\u001b[38;5;241m.\u001b[39mappend(textbook_dict[textbook][i])\n\u001b[1;32m---> 11\u001b[0m         sentiment \u001b[38;5;241m=\u001b[39m one_textbook(to_append_to_messages, query)\n\u001b[0;32m     12\u001b[0m         sentiments[textbook] \u001b[38;5;241m=\u001b[39m sentiment\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiments\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mone_textbook\u001b[1;34m(textbook_appendage, query)\u001b[0m\n\u001b[0;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: query}]\n\u001b[0;32m     12\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: to_append})\n\u001b[1;32m---> 14\u001b[0m     answer \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     15\u001b[0m             model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m             messages \u001b[38;5;241m=\u001b[39m messages\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     19\u001b[0m     answers\u001b[38;5;241m.\u001b[39mappend(answer\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m     21\u001b[0m total_textbook_sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    665\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    666\u001b[0m             {\n\u001b[0;32m    667\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    668\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    669\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    670\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    671\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    672\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    673\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    674\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    675\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    676\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    677\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    678\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    679\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    680\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    681\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    682\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    683\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    687\u001b[0m             },\n\u001b[0;32m    688\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    689\u001b[0m         ),\n\u001b[0;32m    690\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    691\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    692\u001b[0m         ),\n\u001b[0;32m    693\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    694\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    695\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    696\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1199\u001b[0m     )\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    890\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    891\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    892\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    893\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    894\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    895\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    966\u001b[0m         options,\n\u001b[0;32m    967\u001b[0m         cast_to,\n\u001b[0;32m    968\u001b[0m         retries,\n\u001b[0;32m    969\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    970\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    971\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    972\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1014\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1016\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1017\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1018\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1019\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:965\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m    964\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    966\u001b[0m         options,\n\u001b[0;32m    967\u001b[0m         cast_to,\n\u001b[0;32m    968\u001b[0m         retries,\n\u001b[0;32m    969\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    970\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    971\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    972\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1014\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1015\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1016\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m   1017\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1018\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1019\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    988\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-kRjsegsmHRFN0vGELEEXRooK on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# all_sentiments = all_textbooks(title_text, test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5e247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textbook:  Abn_Barlow_04_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_05_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_06_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_07_Transgender_v2.docx\n",
      "textbook:  Abn_Barlow_08_Transgender.docx\n",
      "textbook:  Abn_Brown_05_Transgender.docx\n",
      "textbook:  Abn_Comer_05_Transgender_v2.docx\n",
      "textbook:  Abn_Comer_06_Transgender.docx\n",
      "textbook:  Abn_Comer_07_Transgender.docx\n",
      "textbook:  Abn_Comer_08_Transgender_v2.docx\n",
      "textbook:  Abn_Comer_09_Transgender.docx\n",
      "textbook:  Abn_Hooley_13_Transgender.docx\n",
      "textbook:  Abn_Hooley_14_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_15_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_16_Transgender_v2.docx\n",
      "textbook:  Abn_Hooley_17_Transgender.docx\n",
      "textbook:  Abn_Kearney_06_Transgender.docx\n",
      "textbook:  Abn_Mash_02_Transgender.docx\n",
      "textbook:  Abn_Mash_05_Transgender.docx\n",
      "textbook:  Abn_Mash_06_Transgender.docx\n",
      "textbook:  Abn_Nevid_08_Transgender_v2.docx\n",
      "textbook:  Abn_Nevid_09_Transgender.docx\n",
      "textbook:  Abn_Nevid_10_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_03_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_04_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_05_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_06_Transgender.docx\n",
      "textbook:  Abn_Nolen-Hoeksema_07_Transgender.docx\n",
      "textbook:  Abn_Sue_07_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_08_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_09_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_10_Transgender_v2.docx\n",
      "textbook:  Abn_Sue_11_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_04_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_05_Transgender_v2.docx\n",
      "textbook:  Abn_Whitbourne_06_Transgender.docx\n",
      "textbook:  Abn_Whitbourne_07_Transgender_v2.docx\n",
      "textbook:  Abn_Whitbourne_08_Transgender.docx\n",
      "textbook:  Devo_Berger_05_Transgender.docx\n",
      "textbook:  Devo_Berger_06_Transgender.docx\n",
      "textbook:  Devo_Berger_07_Transgender.docx\n",
      "textbook:  Devo_Berger_08_Transgender.docx\n",
      "textbook:  Devo_Berger_09_Transgender.docx\n",
      "textbook:  Devo_Berger_10_Transgender.docx\n",
      "textbook:  Devo_Berk_08_Transgender.docx\n",
      "textbook:  Devo_Bornstein_02_Transgender.docx\n",
      "textbook:  Devo_Bornstein_04_Transgender_v2.docx\n",
      "textbook:  Devo_Bornstein_05_Transgender_v2.docx\n",
      "textbook:  Devo_Bornstein_07_Transgender.docx\n",
      "textbook:  Devo_Feldman_03_Transgender.docx\n",
      "textbook:  Devo_Feldman_04_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_05_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_06_Transgender_v2.docx\n",
      "textbook:  Devo_Feldman_07_Transgender.docx\n",
      "textbook:  Devo_Feldman_08_Transgender.docx\n",
      "textbook:  Devo_Gonzalez-Mena_10_Transgender.docx\n",
      "textbook:  Devo_Gonzalez-Mena_11_Transgender.docx\n",
      "textbook:  Devo_Kail_02_Transgender.docx\n",
      "textbook:  Devo_Kail_05_Transgender.docx\n",
      "textbook:  Devo_Kail_06_Transgender.docx\n",
      "textbook:  Devo_Kail_07_Transgender.docx\n",
      "textbook:  Devo_Miller_06_Transgender.docx\n",
      "textbook:  Devo_Newman_08_Transgender.docx\n",
      "textbook:  Devo_Newman_09_Transgender.docx\n",
      "textbook:  Devo_Newman_10_Transgender_v2.docx\n",
      "textbook:  Devo_Newman_11_Transgender.docx\n",
      "textbook:  Devo_Newman_12_Transgender.docx\n",
      "textbook:  Devo_Newman_13_Transgender.docx\n",
      "textbook:  Devo_Santrock_11_Transgender.docx\n",
      "textbook:  Devo_Santrock_12_Transgender.docx\n",
      "textbook:  Devo_Santrock_13_Transgender.docx\n",
      "textbook:  Devo_Santrock_14_Transgender.docx\n",
      "textbook:  Devo_Santrock_15_Transgender_V2.docx\n",
      "textbook:  Devo_Santrock_16_Transgender.docx\n",
      "textbook:  Devo_Sigelman_05_Transgender.docx\n",
      "textbook:  Devo_Sigelman_07_Transgender.docx\n",
      "textbook:  Devo_Sigelman_08_Transgender.docx\n",
      "textbook:  Devo_Sigelman_09_Transgender.docx\n",
      "textbook:  GS_Andersen_07_Transgender_v2.docx\n",
      "textbook:  GS_Andersen_08_Transgender_v2.docx\n",
      "textbook:  GS_Andersen_09_Transgender.docx\n",
      "textbook:  GS_Brannon_05_Transgender_v2.docx\n",
      "textbook:  GS_Brannon_06_Transgender.docx\n",
      "textbook:  GS_Brannon_07_Transgender.docx\n",
      "textbook:  GS_Healey_03_Transgender_v2.docx\n",
      "textbook:  GS_Healey_04_Transgender.docx\n",
      "textbook:  GS_Healey_05_Transgender.docx\n",
      "textbook:  GS_Helgeson_03_Transgender_v2.docx\n",
      "textbook:  GS_Helgeson_04_Transgender_v2.docx\n",
      "textbook:  GS_Helgeson_05_Transgender.docx\n",
      "textbook:  GS_Kimmel_04_Transgender_v2.docx\n",
      "textbook:  GS_Kimmel_05_Transgender_v2.docx\n",
      "textbook:  GS_Kimmel_06_Transgender.docx\n",
      "textbook:  GS_Newman_01_Transgender_v2.docx\n",
      "textbook:  GS_Newman_02_Transgender_v2.docx\n",
      "textbook:  GS_Newman_03_Transgender.docx\n",
      "textbook:  GS_Robinson_02_Transgender.docx\n",
      "textbook:  GS_Robinson_03_Transgender_v2.docx\n",
      "textbook:  GS_Robinson_04_Transgender.docx\n",
      "textbook:  GS_Rothenberg_08_Transgender_v2.docx\n",
      "textbook:  GS_Rothenberg_09_Transgender_v2.docx\n",
      "textbook:  GS_Rothenberg_10_Transgender.docx\n",
      "textbook:  GS_Wood_10_Transgender_v2.docx\n",
      "textbook:  GS_Wood_11_Transgender_v2.docx\n",
      "textbook:  GS_Wood_12_Transgender.docx\n",
      "textbook:  HS_Carroll_03_Transgender.docx\n",
      "textbook:  HS_Carroll_04_Transgender.docx\n",
      "textbook:  HS_Carroll_05_Transgender.docx\n",
      "textbook:  HS_Crooks_11_Transgender.docx\n",
      "textbook:  HS_Crooks_12_Transgender_v2.docx\n",
      "textbook:  HS_Crooks_13_Transgender.docx\n",
      "textbook:  HS_Greenberg_04_Transgender.docx\n",
      "textbook:  HS_Greenberg_05_Transgender_v2.docx\n",
      "textbook:  HS_Greenberg_06_Transgender.docx\n",
      "textbook:  HS_Hock_02_Transgender.docx\n",
      "textbook:  HS_Hock_03_Transgender.docx\n",
      "textbook:  HS_Hock_04_Transgender.docx\n",
      "textbook:  HS_Hyde_11_Transgender_v2.docx\n",
      "textbook:  HS_Hyde_12_Transgender_v2.docx\n",
      "textbook:  HS_Hyde_13_Transgender.docx\n",
      "textbook:  HS_LeVay_01_Transgender.docx\n",
      "textbook:  HS_LeVay_02_Transgender.docx\n",
      "textbook:  HS_LeVay_03_Transgender.docx\n",
      "textbook:  HS_Yarber_07_Transgender.docx\n",
      "textbook:  HS_Yarber_08_Transgender.docx\n",
      "textbook:  HS_Yarber_09_Transgender.docx\n",
      "textbook:  Intro_Bernstein_06_Transgender.docx\n",
      "textbook:  Intro_Bernstein_07_Transgender_v2.docx\n",
      "textbook:  Intro_Bernstein_08_Transgender.docx\n",
      "textbook:  Intro_Bernstein_09_Transgender_v2.docx\n",
      "textbook:  Intro_Bernstein_10_Transgender.docx\n",
      "textbook:  Intro_Coon_10_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_11_Transgender.docx\n",
      "textbook:  Intro_Coon_12_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_13_Transgender_v2.docx\n",
      "textbook:  Intro_Coon_14_Transgender.docx\n",
      "textbook:  Intro_Griggs_01_Transgender.docx\n",
      "textbook:  Intro_Griggs_04_Transgender.docx\n",
      "textbook:  Intro_Griggs_05_Transgender.docx\n",
      "textbook:  Intro_Kalat_08_Transgender.docx\n",
      "textbook:  Intro_Kalat_11_Transgender.docx\n",
      "textbook:  Intro_Morris_07_Transgender_v2.docx\n",
      "textbook:  Intro_Morris_09_Transgender.docx\n",
      "textbook:  Intro_Morris_10_Transgender.docx\n",
      "textbook:  Intro_Morris_11_Transgender.docx\n",
      "textbook:  Intro_Myers_07_Transgender.docx\n",
      "textbook:  Intro_Myers_08_Transgender.docx\n",
      "textbook:  Intro_Myers_09_Transgender.docx\n",
      "textbook:  Intro_Myers_10_Transgender.docx\n",
      "textbook:  Intro_Myers_11_Transgender.docx\n",
      "textbook:  Intro_Nevid_01_Transgender.docx\n",
      "textbook:  Intro_Nevid_02_Transgender_v2.docx\n",
      "textbook:  Intro_Nevid_03_Transgender_v2.docx\n",
      "textbook:  Intro_Nevid_04_Transgender.docx\n",
      "textbook:  Intro_Nevid_05_Transgender.docx\n",
      "textbook:  Intro_Rathus_01_Transgender.docx\n",
      "textbook:  Intro_Rathus_02_Transgender.docx\n",
      "textbook:  Intro_Rathus_03_Transgender.docx\n",
      "textbook:  Intro_Rathus_04_Transgender.docx\n",
      "textbook:  Intro_Rathus_05_Transgender.docx\n",
      "textbook:  Intro_Wade_08_Transgender_v2.docx\n",
      "textbook:  Intro_Wade_09_Transgender.docx\n",
      "textbook:  Intro_Wade_11_Transgender_v2.docx\n",
      "textbook:  Intro_Wade_12_Transgender.docx\n",
      "textbook:  Intro_Weiten_07_Transgender.docx\n",
      "textbook:  Intro_Weiten_08_Transgender_v2.docx\n",
      "textbook:  Intro_Weiten_09_Transgender_v2.docx\n",
      "textbook:  Intro_Weiten_10_Transgender.docx\n",
      "textbook:  Neuro_Bear_03_Transgender.docx\n",
      "textbook:  Neuro_Bear_04_Transgender.docx\n",
      "textbook:  Neuro_Breedlove_05_Transgender.docx\n",
      "textbook:  Neuro_Breedlove_06_Transgender.docx\n",
      "textbook:  Neuro_Breedlove_07_Transgender.docx\n",
      "textbook:  Neuro_Breedlove_08_Transgender.docx\n",
      "textbook:  Neuro_Carlson_09_Transgender.docx\n",
      "textbook:  Neuro_Carlson_10_Transgender_v2.docx\n",
      "textbook:  Neuro_Carlson_11_Transgender_v2.docx\n",
      "textbook:  Neuro_Carlson_12_Transgender.docx\n",
      "textbook:  Neuro_Garrett_02_Transgender.docx\n",
      "textbook:  Neuro_Garrett_03_Transgender.docx\n",
      "textbook:  Neuro_Garrett_04_Transgender_v2.docx\n",
      "textbook:  Neuro_Garrett_05_Transgender.docx\n",
      "textbook:  Neuro_Haines_05_Transgender.docx\n",
      "textbook:  Neuro_Johnson_04_Transgender.docx\n",
      "textbook:  Neuro_Kalat_12_Transgender.docx\n",
      "textbook:  Neuro_Kolb_07_Transgender.docx\n",
      "textbook:  Neuro_Pinel_07_Transgender.docx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textbook:  Neuro_Pinel_08_Transgender.docx\n",
      "textbook:  Neuro_Pinel_09_Transgender_v2.docx\n",
      "textbook:  Neuro_Pinel_10_Transgender.docx\n",
      "textbook:  Neuro_Reisberg_06_Transgender.docx\n",
      "textbook:  Socl_Aronson_08_Transgender.docx\n",
      "textbook:  Socl_Aronson_09_Transgender.docx\n",
      "textbook:  Socl_Baumeister_02_Transgender.docx\n",
      "textbook:  Socl_Baumeister_04_Transgender.docx\n",
      "textbook:  Socl_Branscombe_12_Transgender.docx\n",
      "textbook:  Socl_Branscombe_13_Transgender_v2.docx\n",
      "textbook:  Socl_Branscombe_14_Transgender.docx\n",
      "textbook:  Socl_Franzoi_05_Transgender.docx\n",
      "textbook:  Socl_Franzoi_06_Transgender.docx\n",
      "textbook:  Socl_Franzoi_07_Transgender.docx\n",
      "textbook:  Socl_Gilovich_02_Transgender.docx\n",
      "textbook:  Socl_Gilovich_03_Transgender.docx\n",
      "textbook:  Socl_Gilovich_04_Transgender.docx\n",
      "textbook:  Socl_Gruman_02_Transgender.docx\n",
      "textbook:  Socl_Gruman_03_Transgender.docx\n",
      "textbook:  Socl_Kassin_09_Transgender.docx\n",
      "textbook:  Socl_Kassin_10_Transgender.docx\n",
      "textbook:  Socl_Myers_10_Transgender.docx\n",
      "textbook:  Socl_Myers_11_Transgender.docx\n",
      "textbook:  Socl_Myers_12_Transgender.docx\n",
      "textbook:  Socl_Rogers_02_Transgender.docx\n",
      "textbook:  Socl_Rogers_03_Transgender_v2.docx\n",
      "textbook:  Socl_Rogers_04_Transgender.docx\n",
      "textbook:  Socl_Zastrow_08_Transgender.docx\n",
      "textbook:  Socl_Zastrow_09_Transgender.docx\n",
      "textbook:  Socl_Zastrow_10_Transgender.docx\n",
      "textbook:  Spcl_Friend_02_Transgender.docx\n",
      "textbook:  Spcl_Friend_03_Transgender.docx\n",
      "textbook:  Spcl_Friend_04_Transgender.docx\n",
      "textbook:  Spcl_Friend_05_Transgender.docx\n",
      "textbook:  Spcl_Gargiulo_06_Transgender.docx\n",
      "textbook:  Spcl_Hardman_10_Transgender.docx\n",
      "textbook:  Spcl_Hardman_12_Transgender.docx\n",
      "textbook:  Spcl_Heward_10_Transgender.docx\n",
      "textbook:  Spcl_Heward_11_Transgender.docx\n",
      "textbook:  Spcl_Kuder_05_Transgender.docx\n",
      "textbook:  Spcl_Lewis_09_Transgender.docx\n",
      "textbook:  Spcl_Overton_08_Transgender.docx\n",
      "textbook:  Spcl_Smith_04_Transgender.docx\n",
      "textbook:  Spcl_Smith_05_Transgender.docx\n",
      "textbook:  Spcl_Smith_07_Transgender.docx\n",
      "textbook:  Spcl_Turnbull_04_Transgender.docx\n",
      "textbook:  Spcl_Turnbull_05_Transgender.docx\n",
      "textbook:  Spcl_Turnbull_06_Transgender.docx\n",
      "textbook:  Spcl_Turnbull_07_Transgender.docx\n",
      "textbook:  Spcl_Turnbull_08_Transgender.docx\n",
      "textbook:  Spcl_Vaughn_07_Transgender.docx\n"
     ]
    }
   ],
   "source": [
    "# To save progress in case an error comes up\n",
    "\n",
    "all_sentiments = {}\n",
    "for textbook in title_text:\n",
    "    print(\"textbook: \", textbook)\n",
    "    to_append_to_messages = []\n",
    "    for i in range(len(title_text[textbook])):\n",
    "#             print(\"thing: \", i)\n",
    "        to_append_to_messages.append(title_text[textbook][i])\n",
    "    sentiment = one_textbook(to_append_to_messages, test_query)\n",
    "    all_sentiments[textbook] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cb59079",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmp_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\GitHub_DMP\\Results\"\n",
    "\n",
    "os.chdir(dmp_dir)\n",
    "\n",
    "all_sentiments_df = pd.DataFrame(all_sentiments, index = [0])\n",
    "all_sentiments_df.to_csv('chatgpt_sentiments_transgender_03_13_2024.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb066a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361be0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
