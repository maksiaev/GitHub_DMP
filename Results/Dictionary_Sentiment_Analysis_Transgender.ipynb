{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a95c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Alexander Maksiaev\n",
    "# Purpose: Sentiment analysis of textbooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b97008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv \n",
    "import docx\n",
    "from english_words import get_english_words_set\n",
    "import enchant\n",
    "import inflect\n",
    "\n",
    "# Find real English words\n",
    "web2lowerset = get_english_words_set(['web2'], lower=True)\n",
    "\n",
    "# Switch into textbook directory\n",
    "os.getcwd()\n",
    "\n",
    "textbook_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\Textbook_Dump_Transgender\"\n",
    "\n",
    "textbooks = os.listdir(textbook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353ef867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean scored dictionary for use\n",
    "\n",
    "dictionary_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\GitHub_DMP\"\n",
    "\n",
    "dictionary_location = os.chdir(dictionary_dir)\n",
    "        \n",
    "dictionary_clean = []\n",
    "with open(\"final_dictionary.txt\", newline = '\\n') as dictionary: \n",
    "    dictionary_reader = csv.reader(dictionary, delimiter='\\t')\n",
    "    # Only include words that have scores\n",
    "    for i in dictionary_reader:\n",
    "        if i[1] != \"0\": # If the word has a score\n",
    "            dictionary_clean.append(i)\n",
    "\n",
    "# More cleanup\n",
    "for i in dictionary_clean:\n",
    "    i[1] = float(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8b6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to textbook directory \n",
    "\n",
    "os.chdir(textbook_dir)\n",
    "\n",
    "# Function to get full text\n",
    "def getText(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return fullText\n",
    "\n",
    "# Dictionary filled with text for all the books, minus the titles\n",
    "title_text = {}\n",
    "for book in textbooks:\n",
    "    total_text = getText(book)\n",
    "    text_without_title = total_text[4:]\n",
    "    for piece in text_without_title:\n",
    "        if piece == '':\n",
    "            text_without_title.remove(piece) # Does not get rid of all whitespace, but ah well.\n",
    "    title_text[book] = text_without_title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b841a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc31b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from each book\n",
    "\n",
    "stopwords_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\GitHub_DMP\\Stop_Words\" \n",
    "\n",
    "os.chdir(stopwords_dir)\n",
    "\n",
    "f = open(\"stop_words_english_modified.txt\", \"r\", encoding=\"utf-8\")\n",
    "stopwords = []\n",
    "for text in f:\n",
    "    text = text.replace('\\n', '')\n",
    "    stopwords.append(text)\n",
    "\n",
    "\n",
    "punc = '''!()[]{};:'-\"\\,<>./?@#$%^&*_~''' # Must include \"-\" in words... or not?\n",
    "\n",
    "# Function to clean up text and remove stopwords\n",
    "def clean(book):\n",
    "    text_list = title_text[book]\n",
    "    new_text_list = []\n",
    "    \n",
    "    # Clean up text\n",
    "    for text in text_list:\n",
    "        text = text.strip()\n",
    "        text = text.lower()\n",
    "        text = text.split(' ')\n",
    "        new_text_list.append(text)\n",
    "\n",
    "\n",
    "    newer_text_list = []\n",
    "    \n",
    "    # Remove punctuation\n",
    "    for sentence in new_text_list:\n",
    "        for word in sentence:\n",
    "            for char in punc:\n",
    "                if char in word:\n",
    "                    word = word.replace(char, '')\n",
    "            newer_text_list.append(word)\n",
    "                \n",
    "    # Remove stop words\n",
    "    newest_text_list = []\n",
    "    for words in newer_text_list:\n",
    "        if words not in stopwords:\n",
    "            newest_text_list.append(words)\n",
    "\n",
    "    # Remove blanks\n",
    "    for w in newest_text_list:\n",
    "        if len(w) == 0:\n",
    "            newest_text_list.remove(w)\n",
    "            \n",
    "    return newest_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1082e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8aa26a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['417', 'dsmivtr', 'criteria', 'diagnosis', 'gender', 'identity', 'disorder', 'people', 'gender', 'identity', 'disorder', 'born', 'wrong', 'sexs', 'genitals', 'members', 'sex', 'strong', 'persistent', 'identification', 'sex', 'children', 'manifested', '1', 'repeatedly', 'stated', 'desire', 'insistence', 'sex', '2', 'boys', 'preference', 'crossdressing', 'simulating', 'female', 'attire', 'girls', 'insistence', 'wearing', 'stereotypic', 'masculine', 'clothing', '3', 'strong', 'persistent', 'preferences', 'crosssex', 'roles', 'play', 'fantasies', '4', 'intense', 'desire', 'participate', 'stereotypic', 'games', 'pastimes', 'sex', '5', 'strong', 'preference', 'playmates', 'sex', 'adolescents', 'adults', 'identification', 'sex', 'manifested', 'symptoms', 'stated', 'desire', 'sex', 'frequently', 'passing', 'sex', 'desire', 'live', 'treated', 'sex', 'conviction', 'typical', 'feelings', 'reactions', 'sex', 'persistent', 'discomfort', 'sex', 'sense', 'inappropriateness', 'gender', 'role', 'sex', 'disturbance', 'concurrent', 'physical', 'intersex', 'condition', 'distress', 'problems', 'functioning', '417', 'boys', 'referred', 'girls', 'concerns', 'gender', 'identity', 'reflect', 'greater', 'prevalence', 'gender', 'identity', 'disorder', 'males', 'females', 'reflect', 'parents', 'concerned', 'violations', 'gender', 'roles', 'boys', 'girls', 'zucker', 'cohenkettenis', '2008', '417', 'adults', 'diagnosed', 'gender', 'identity', 'disorder', 'referred', 'transsexuals', 'term', 'transgender', 'broadly', 'refers', 'individuals', 'varying', 'degrees', 'crossgender', 'identity', 'including', 'transsexuals', 'individuals', 'crossdress', 'transvestic', 'fetishism', 'lawrence', '2008', 'people', 'gender', 'identity', 'disorder', 'crossdress', 'sexually', 'aroused', 'practice', 'simply', 'putting', 'clothes', 'gender', 'belong', 'sexual', 'preferences', 'individuals', 'gender', 'identity', 'disorder', 'vary', 'asexual', 'sex', 'heterosexual', 'homosexual', 'lawrence', '2008', 'people', 'gender', 'identity', 'disorder', 'afford', 'seek', 'sexchange', 'operation', 'gender', 'identity', 'disorder', 'rare', 'estimated', 'prevalence', '1', '12900', 'male', 'female', 'transsexualism', '1', '33800', 'female', 'male', 'transsexualism', 'cuypere', '2007', '417', 'transsexual', 'people', 'disturbed', 'misassignment', 'gender', 'develop', 'alcohol', 'drug', 'abuse', 'problems', 'andor', 'psychological', 'disorders', 'lawrence', '2008', 'low', 'selfesteem', 'psychological', 'distress', 'result', 'rejection', 'high', 'rates', 'hiv', 'infection', 'transsexual', 'people', 'reported', 'studies', 'lawrence', '2008', 'hiv', 'contracted', 'risky', 'sexual', 'behaviors', 'sharing', 'needles', 'drug', 'hormone', 'injections', 'transsexual', 'people', 'avoid', 'seeking', 'medical', 'attention', 'negative', 'interactions', 'physicians', 'physicians', 'refuse', 'treat', 'transsexual', 'people', '417', 'dsm5', 'authors', 'propose', 'replacing', 'label', 'gender', 'identity', 'disorder', 'gender', 'incongruence', 'label', 'accurately', 'reflects', 'core', 'problem', 'incongruence', 'identity', 'individuals', 'experience', 'andor', 'express', 'expected', 'live', 'based', 'assigned', 'gender', 'birth', 'meyerbahlburg', '2009', 'winters', '2005', 'survey', 'transgendered', 'people', 'rejected', 'term', 'gender', 'identity', 'disorder', 'contributes', 'stigmatization', 'condition', 'vance', 'press', 'dsm5', 'gender', 'incongruence', 'manifested', 'subjective', 'sense', 'feelings', 'identity', 'gender', 'strong', 'desires', 'rid', 'genitals', 'genitals', 'gender', 'desire', 'treated', 'gender', 'american', 'psychiatric', 'association', '2010', '537', 'transsexuals', 'people', 'experience', 'chronic', 'discomfort', 'gender', 'genitals', 'desire', 'rid', 'genitals', 'live', 'member', 'sex']\n"
     ]
    }
   ],
   "source": [
    "# Update all the books with their clean, stopword-less counterparts\n",
    "\n",
    "clean_texts = {}\n",
    "for book in title_text:\n",
    "    newest_text_list = clean(book)\n",
    "    clean_texts[book] = newest_text_list\n",
    "    \n",
    "print(clean_texts[\"Abn_Nolen-Hoeksema_05_Transgender.docx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c983e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find sentiment score of the cleaned textbooks\n",
    "\n",
    "def get_sentiment(clean_textbook):\n",
    "    total_score = 0\n",
    "    for piece in clean_textbook:\n",
    "        for word in dictionary_clean:\n",
    "            if piece == word[0]: # If the word in the textbook is in the dictionary\n",
    "                total_score += word[1] # Add that word's score to the total score\n",
    "    total_score = total_score/(len(clean_textbook))\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea500af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11996583481877626\n"
     ]
    }
   ],
   "source": [
    "print(get_sentiment(clean_texts[\"Abn_Nolen-Hoeksema_05_Transgender.docx\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c34a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find raw sentiments and see if length matters\n",
    "\n",
    "def get_raw_sentiment(clean_textbook):\n",
    "    total_score = 0\n",
    "    for piece in clean_textbook:\n",
    "        for word in dictionary_clean:\n",
    "            if piece == word[0]: # If the word in the textbook is in the dictionary\n",
    "                total_score += word[1] # Add that word's score to the total score\n",
    "    return total_score\n",
    "\n",
    "# Now, find sentiment score of all of the books\n",
    "\n",
    "dmp_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\GitHub_DMP\\Results\"\n",
    "\n",
    "os.chdir(dmp_dir)\n",
    "\n",
    "sentiments = {}\n",
    "for textbook in textbooks:\n",
    "    book = clean_texts[textbook]\n",
    "    sentiment = get_sentiment(book)\n",
    "    sentiments[textbook] = sentiment\n",
    "    \n",
    "all_sentiments = pd.DataFrame(sentiments, index = [0])\n",
    "\n",
    "all_sentiments.to_csv('sentiments_02_17_2024_transgender.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494c7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
