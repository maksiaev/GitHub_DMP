{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451586ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Alexander Maksiaev\n",
    "# Purpose: Create the dictionary used for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cd861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping: Importing libraries, switching directories, etc.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv \n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "results_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\Results\"\n",
    "\n",
    "results = os.listdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea8b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             StartDate  \\\n",
      "0                                           Start Date   \n",
      "1    {\"ImportId\":\"startDate\",\"timeZone\":\"America/De...   \n",
      "2                                  2023-11-05 14:39:31   \n",
      "3                                  2023-11-06 14:32:51   \n",
      "4                                  2023-11-06 16:33:32   \n",
      "..                                                 ...   \n",
      "529                                2023-11-19 17:29:19   \n",
      "530                                2023-11-17 12:56:00   \n",
      "531                                2023-11-18 21:07:12   \n",
      "532                                2023-11-19 20:00:38   \n",
      "533                                2023-11-19 20:42:51   \n",
      "\n",
      "                                               EndDate                 Status  \\\n",
      "0                                             End Date          Response Type   \n",
      "1    {\"ImportId\":\"endDate\",\"timeZone\":\"America/Denv...  {\"ImportId\":\"status\"}   \n",
      "2                                  2023-11-05 14:46:00                      1   \n",
      "3                                  2023-11-06 14:40:13                      0   \n",
      "4                                  2023-11-06 16:42:10                      0   \n",
      "..                                                 ...                    ...   \n",
      "529                                2023-11-19 17:41:30                      0   \n",
      "530                                2023-11-19 20:03:46                      0   \n",
      "531                                2023-11-19 20:09:48                      0   \n",
      "532                                2023-11-19 20:16:55                      0   \n",
      "533                                2023-11-19 20:53:36                      0   \n",
      "\n",
      "                    IPAddress                 Progress  \\\n",
      "0                  IP Address                 Progress   \n",
      "1    {\"ImportId\":\"ipAddress\"}  {\"ImportId\":\"progress\"}   \n",
      "2                         NaN                      100   \n",
      "3                 76.104.6.49                      100   \n",
      "4               71.62.224.194                      100   \n",
      "..                        ...                      ...   \n",
      "529            199.111.213.38                      100   \n",
      "530            216.30.189.201                      100   \n",
      "531           199.111.213.126                      100   \n",
      "532             74.96.253.236                      100   \n",
      "533            75.102.136.114                      100   \n",
      "\n",
      "       Duration (in seconds)                 Finished  \\\n",
      "0      Duration (in seconds)                 Finished   \n",
      "1    {\"ImportId\":\"duration\"}  {\"ImportId\":\"finished\"}   \n",
      "2                        389                        1   \n",
      "3                        442                        1   \n",
      "4                        518                        1   \n",
      "..                       ...                      ...   \n",
      "529                      730                        1   \n",
      "530                   198465                        1   \n",
      "531                    82955                        1   \n",
      "532                      976                        1   \n",
      "533                      644                        1   \n",
      "\n",
      "                                          RecordedDate  \\\n",
      "0                                        Recorded Date   \n",
      "1    {\"ImportId\":\"recordedDate\",\"timeZone\":\"America...   \n",
      "2                                  2023-11-05 14:46:18   \n",
      "3                                  2023-11-06 14:40:17   \n",
      "4                                  2023-11-06 16:42:17   \n",
      "..                                                 ...   \n",
      "529                                2023-11-19 17:41:34   \n",
      "530                                2023-11-19 20:03:50   \n",
      "531                                2023-11-19 20:09:49   \n",
      "532                                2023-11-19 20:16:56   \n",
      "533                                2023-11-19 20:53:37   \n",
      "\n",
      "                   ResponseId                 RecipientLastName  ...  \\\n",
      "0                 Response ID               Recipient Last Name  ...   \n",
      "1    {\"ImportId\":\"_recordId\"}  {\"ImportId\":\"recipientLastName\"}  ...   \n",
      "2           R_2Cq30qvnrGFGz2p                               NaN  ...   \n",
      "3           R_3agGnJU2rEebGzn                               NaN  ...   \n",
      "4           R_1LnuReROe82Wda1                               NaN  ...   \n",
      "..                        ...                               ...  ...   \n",
      "529         R_3CIqdGyT7CjisnK                               NaN  ...   \n",
      "530         R_UhfdxvRCbSsepjP                               NaN  ...   \n",
      "531         R_1fjWjqE5nJrXMOl                               NaN  ...   \n",
      "532         R_3hF17DRKzioorIS                               NaN  ...   \n",
      "533         R_32Mb9oiKgzHGpkB                               NaN  ...   \n",
      "\n",
      "                    QID10831                 QID10832  \\\n",
      "0                    weights              impairments   \n",
      "1    {\"ImportId\":\"QID10831\"}  {\"ImportId\":\"QID10832\"}   \n",
      "2                        NaN                      NaN   \n",
      "3                        NaN                      NaN   \n",
      "4                        NaN                      NaN   \n",
      "..                       ...                      ...   \n",
      "529                      NaN                      NaN   \n",
      "530                      NaN                      NaN   \n",
      "531                      NaN                      NaN   \n",
      "532                      NaN                      NaN   \n",
      "533                      NaN                      NaN   \n",
      "\n",
      "                    QID10833                        QID10834  \\\n",
      "0                  terrorist  Please choose the option [+3].   \n",
      "1    {\"ImportId\":\"QID10833\"}         {\"ImportId\":\"QID10834\"}   \n",
      "2                        NaN                             NaN   \n",
      "3                        NaN                             NaN   \n",
      "4                        NaN                             NaN   \n",
      "..                       ...                             ...   \n",
      "529                      NaN                             NaN   \n",
      "530                      NaN                             NaN   \n",
      "531                      NaN                             NaN   \n",
      "532                      NaN                             NaN   \n",
      "533                      NaN                             NaN   \n",
      "\n",
      "                                                Q10051  \\\n",
      "0    Below are some questions for demographic purpo...   \n",
      "1                              {\"ImportId\":\"QID11055\"}   \n",
      "2                                                  NaN   \n",
      "3                                                  NaN   \n",
      "4                                                  NaN   \n",
      "..                                                 ...   \n",
      "529                                                NaN   \n",
      "530                                                NaN   \n",
      "531                                                NaN   \n",
      "532                                                NaN   \n",
      "533                                                NaN   \n",
      "\n",
      "                                      Q11051                   Q11052  \\\n",
      "0    How old are you? Please enter a number.       What year are you?   \n",
      "1               {\"ImportId\":\"QID11051_TEXT\"}  {\"ImportId\":\"QID11052\"}   \n",
      "2                                        NaN                      NaN   \n",
      "3                                        NaN                      NaN   \n",
      "4                                         20                        3   \n",
      "..                                       ...                      ...   \n",
      "529                                       18                        1   \n",
      "530                                       22                        4   \n",
      "531                                       19                        1   \n",
      "532                                       18                        1   \n",
      "533                                       19                        2   \n",
      "\n",
      "                                               Q11053  \\\n",
      "0    Are you a Psychology or Cognitive Science major?   \n",
      "1                             {\"ImportId\":\"QID11053\"}   \n",
      "2                                                 NaN   \n",
      "3                                                 NaN   \n",
      "4                                                   2   \n",
      "..                                                ...   \n",
      "529                                                 2   \n",
      "530                                                 2   \n",
      "531                                                 2   \n",
      "532                                                 2   \n",
      "533                                                 2   \n",
      "\n",
      "                                                Q11054  \\\n",
      "0    Have you learned about autism in any UVa cours...   \n",
      "1                              {\"ImportId\":\"QID11054\"}   \n",
      "2                                                  NaN   \n",
      "3                                                  NaN   \n",
      "4                                                    1   \n",
      "..                                                 ...   \n",
      "529                                                  1   \n",
      "530                                                  2   \n",
      "531                                                  2   \n",
      "532                                                  2   \n",
      "533                                                  2   \n",
      "\n",
      "                                                Q11049  \n",
      "0    Debriefing Form\\nProtocol #: 6251: Sentiment A...  \n",
      "1                              {\"ImportId\":\"QID11049\"}  \n",
      "2                                                    1  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "..                                                 ...  \n",
      "529                                                NaN  \n",
      "530                                                NaN  \n",
      "531                                                NaN  \n",
      "532                                                NaN  \n",
      "533                                                NaN  \n",
      "\n",
      "[534 rows x 10068 columns]\n",
      "534\n"
     ]
    }
   ],
   "source": [
    "# Getting the big data frame\n",
    "\n",
    "results_clean = []\n",
    "df = pd.read_csv(\"Sentiment_Analysis_Results_2.csv\", low_memory=False)\n",
    "print(df)\n",
    "print(len(df))\n",
    "original_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a69ead7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    StartDate   EndDate         Status   IPAddress  Progress  \\\n",
      "0  Start Date  End Date  Response Type  IP Address  Progress   \n",
      "\n",
      "   Duration (in seconds)  Finished   RecordedDate   ResponseId  \\\n",
      "0  Duration (in seconds)  Finished  Recorded Date  Response ID   \n",
      "\n",
      "     RecipientLastName  ... QID10831     QID10832   QID10833  \\\n",
      "0  Recipient Last Name  ...  weights  impairments  terrorist   \n",
      "\n",
      "                         QID10834  \\\n",
      "0  Please choose the option [+3].   \n",
      "\n",
      "                                              Q10051  \\\n",
      "0  Below are some questions for demographic purpo...   \n",
      "\n",
      "                                    Q11051              Q11052  \\\n",
      "0  How old are you? Please enter a number.  What year are you?   \n",
      "\n",
      "                                             Q11053  \\\n",
      "0  Are you a Psychology or Cognitive Science major?   \n",
      "\n",
      "                                              Q11054  \\\n",
      "0  Have you learned about autism in any UVa cours...   \n",
      "\n",
      "                                              Q11049  \n",
      "0  Debriefing Form\\nProtocol #: 6251: Sentiment A...  \n",
      "\n",
      "[1 rows x 10068 columns]\n",
      "               StartDate              EndDate         Status        IPAddress  \\\n",
      "0             Start Date             End Date  Response Type       IP Address   \n",
      "3    2023-11-06 14:32:51  2023-11-06 14:40:13              0      76.104.6.49   \n",
      "4    2023-11-06 16:33:32  2023-11-06 16:42:10              0    71.62.224.194   \n",
      "5    2023-11-06 16:29:08  2023-11-06 17:35:16              0   199.111.226.30   \n",
      "6    2023-11-06 16:30:41  2023-11-06 18:13:43              0   199.111.213.85   \n",
      "..                   ...                  ...            ...              ...   \n",
      "529  2023-11-19 17:29:19  2023-11-19 17:41:30              0   199.111.213.38   \n",
      "530  2023-11-17 12:56:00  2023-11-19 20:03:46              0   216.30.189.201   \n",
      "531  2023-11-18 21:07:12  2023-11-19 20:09:48              0  199.111.213.126   \n",
      "532  2023-11-19 20:00:38  2023-11-19 20:16:55              0    74.96.253.236   \n",
      "533  2023-11-19 20:42:51  2023-11-19 20:53:36              0   75.102.136.114   \n",
      "\n",
      "     Progress  Duration (in seconds)  Finished         RecordedDate  \\\n",
      "0    Progress  Duration (in seconds)  Finished        Recorded Date   \n",
      "3         100                    442         1  2023-11-06 14:40:17   \n",
      "4         100                    518         1  2023-11-06 16:42:17   \n",
      "5         100                   3968         1  2023-11-06 17:35:18   \n",
      "6         100                   6181         1  2023-11-06 18:13:48   \n",
      "..        ...                    ...       ...                  ...   \n",
      "529       100                    730         1  2023-11-19 17:41:34   \n",
      "530       100                 198465         1  2023-11-19 20:03:50   \n",
      "531       100                  82955         1  2023-11-19 20:09:49   \n",
      "532       100                    976         1  2023-11-19 20:16:56   \n",
      "533       100                    644         1  2023-11-19 20:53:37   \n",
      "\n",
      "            ResponseId    RecipientLastName  ... QID10831     QID10832  \\\n",
      "0          Response ID  Recipient Last Name  ...  weights  impairments   \n",
      "3    R_3agGnJU2rEebGzn                  NaN  ...      NaN          NaN   \n",
      "4    R_1LnuReROe82Wda1                  NaN  ...      NaN          NaN   \n",
      "5    R_2BmLbg1bz18jTow                  NaN  ...      NaN          NaN   \n",
      "6    R_893QaPQCA0iZ70J                  NaN  ...      NaN          NaN   \n",
      "..                 ...                  ...  ...      ...          ...   \n",
      "529  R_3CIqdGyT7CjisnK                  NaN  ...      NaN          NaN   \n",
      "530  R_UhfdxvRCbSsepjP                  NaN  ...      NaN          NaN   \n",
      "531  R_1fjWjqE5nJrXMOl                  NaN  ...      NaN          NaN   \n",
      "532  R_3hF17DRKzioorIS                  NaN  ...      NaN          NaN   \n",
      "533  R_32Mb9oiKgzHGpkB                  NaN  ...      NaN          NaN   \n",
      "\n",
      "      QID10833                        QID10834  \\\n",
      "0    terrorist  Please choose the option [+3].   \n",
      "3          NaN                             NaN   \n",
      "4          NaN                             NaN   \n",
      "5          NaN                             NaN   \n",
      "6          NaN                             NaN   \n",
      "..         ...                             ...   \n",
      "529        NaN                             NaN   \n",
      "530        NaN                             NaN   \n",
      "531        NaN                             NaN   \n",
      "532        NaN                             NaN   \n",
      "533        NaN                             NaN   \n",
      "\n",
      "                                                Q10051  \\\n",
      "0    Below are some questions for demographic purpo...   \n",
      "3                                                  NaN   \n",
      "4                                                  NaN   \n",
      "5                                                  NaN   \n",
      "6                                                  NaN   \n",
      "..                                                 ...   \n",
      "529                                                NaN   \n",
      "530                                                NaN   \n",
      "531                                                NaN   \n",
      "532                                                NaN   \n",
      "533                                                NaN   \n",
      "\n",
      "                                      Q11051              Q11052  \\\n",
      "0    How old are you? Please enter a number.  What year are you?   \n",
      "3                                        NaN                 NaN   \n",
      "4                                         20                   3   \n",
      "5                                         18                   1   \n",
      "6                                         17                   1   \n",
      "..                                       ...                 ...   \n",
      "529                                       18                   1   \n",
      "530                                       22                   4   \n",
      "531                                       19                   1   \n",
      "532                                       18                   1   \n",
      "533                                       19                   2   \n",
      "\n",
      "                                               Q11053  \\\n",
      "0    Are you a Psychology or Cognitive Science major?   \n",
      "3                                                 NaN   \n",
      "4                                                   2   \n",
      "5                                                   2   \n",
      "6                                                   2   \n",
      "..                                                ...   \n",
      "529                                                 2   \n",
      "530                                                 2   \n",
      "531                                                 2   \n",
      "532                                                 2   \n",
      "533                                                 2   \n",
      "\n",
      "                                                Q11054  \\\n",
      "0    Have you learned about autism in any UVa cours...   \n",
      "3                                                  NaN   \n",
      "4                                                    1   \n",
      "5                                                    2   \n",
      "6                                                    2   \n",
      "..                                                 ...   \n",
      "529                                                  1   \n",
      "530                                                  2   \n",
      "531                                                  2   \n",
      "532                                                  2   \n",
      "533                                                  2   \n",
      "\n",
      "                                                Q11049  \n",
      "0    Debriefing Form\\nProtocol #: 6251: Sentiment A...  \n",
      "3                                                  NaN  \n",
      "4                                                  NaN  \n",
      "5                                                  NaN  \n",
      "6                                                  NaN  \n",
      "..                                                 ...  \n",
      "529                                                NaN  \n",
      "530                                                NaN  \n",
      "531                                                NaN  \n",
      "532                                                NaN  \n",
      "533                                                NaN  \n",
      "\n",
      "[530 rows x 10068 columns]\n",
      "530\n"
     ]
    }
   ],
   "source": [
    "# Cleaning \n",
    "\n",
    "# Study agreement columns: Q11047, Q11050. Only include people who agreed to the study\n",
    "\n",
    "df = df[df['Q11047'] == \"1\"]\n",
    "df = df[df['Q11050'] == \"1\"]\n",
    "words = original_df.iloc[[0]] # Row that has words to form the dictionary\n",
    "print(words)\n",
    "including_words = [words, df]\n",
    "df = pd.concat(including_words, axis=0) # Add the words \n",
    "print(df)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e16c1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Response Type</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Recorded Date</th>\n",
       "      <th>Response ID</th>\n",
       "      <th>Recipient Last Name</th>\n",
       "      <th>...</th>\n",
       "      <th>canning</th>\n",
       "      <th>aims</th>\n",
       "      <th>terrorist</th>\n",
       "      <th>Please choose the option [+3].</th>\n",
       "      <th>Below are some questions for demographic purposes.</th>\n",
       "      <th>How old are you? Please enter a number.</th>\n",
       "      <th>What year are you?</th>\n",
       "      <th>Are you a Psychology or Cognitive Science major?</th>\n",
       "      <th>Have you learned about autism in any UVa courses presently or in the past?</th>\n",
       "      <th>Debriefing Form\\nProtocol #: 6251: Sentiment Analysis \\nThank you for participating in this study! In this study, you rated several words for how\\nnegative or positive they were. We will calculate, for each word, the average rating and\\nuse those averages to be able to objectively quantify the \"sentiment\" of a piece of text.\\nOur particular interest is in assessing the average valence of the words used in sections of\\npopular college-level textbooks that describe autism. We will investigate how the valence\\nhas changed over time, whether textbooks in some sub-fields use more positive or\\nnegative words than others, and so on. This will allow us to understand and document\\nhow attitudes about autism are (or are not) changing in college-level textbooks. Sentiment analysis has been used for a number of purposes, including customer reviews\\nof products or services, social media analysis, and so on. It has also been used in the\\nhumanities to try to quantify the emotions or sentiments in stories and poems. \\nIf you feel especially concerned about any aspects of this study, please feel free to contact\\nProf. Jaswal at jaswal@virginia.edu about options for counseling. Alternatively, you\\ncould also phone the UVA Counseling and Psychological Services (434-243-5556) or the\\nMary D. Ainsworth Psychological Clinic in the psychology department (434-982-4737). \\nThank you for your participation in this study. \\nPlease contact the researchers on the study team listed below to: ● Obtain more information or if you have further questions about the study. ● Report an illness, injury, or other problem. ● Leave the study before it is finished. Vikram Jaswal, Ph.D.\\nProfessor of Psychology\\nDept. of Psychology PO Box 400400\\nUniversity of Virginia\\nCharlottesville, VA 22904-4400 Telephone: (434) 982-4709 Email: jaswal@virginia.edu \\nYou may also report a concern about a study or ask questions about your rights as a\\nresearch subject by contacting the Institutional Review Board listed below. Tonya R. Moon, Ph.D.\\nChair, Institutional Review Board for the Social and Behavioral Sciences One Morton Dr Suite 400\\nUniversity of Virginia, P.O. Box 800392\\nCharlottesville, VA 22908-0392 Telephone: (434) 924-5999 Email: irbsbshelp@virginia.edu Website: https://research.virginia.edu/irb-sbs Website for Research Participants: https://research.virginia.edu/research-participants \\nUVA IRB-SBS # 6251 \\nAdditional Reading: To learn more general information about sentiment analysis, you can visit:\\nhttps://aws.amazon.com/what-is/sentiment-analysis/ Wankhade, M., Rao, A.C.S. &amp; Kulkarni, C. (2022). A survey on sentiment analysis\\nmethods, applications, and challenges. Artificial Intelligence Review, 55, 5731–5780\\n(2022). https://doi.org/10.1007/s10462-022-10144-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>752.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>67607.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7706.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    Start Date  End Date  Response Type  IP Address  Progress  \\\n",
       "0           NaN       NaN            NaN         NaN       NaN   \n",
       "21          NaN       NaN            0.0         NaN     100.0   \n",
       "75          NaN       NaN            0.0         NaN     100.0   \n",
       "109         NaN       NaN            0.0         NaN     100.0   \n",
       "144         NaN       NaN            0.0         NaN     100.0   \n",
       "208         NaN       NaN            0.0         NaN     100.0   \n",
       "247         NaN       NaN            0.0         NaN     100.0   \n",
       "301         NaN       NaN            0.0         NaN     100.0   \n",
       "336         NaN       NaN            0.0         NaN     100.0   \n",
       "451         NaN       NaN            0.0         NaN     100.0   \n",
       "464         NaN       NaN            0.0         NaN     100.0   \n",
       "478         NaN       NaN            0.0         NaN     100.0   \n",
       "\n",
       "0    Duration (in seconds)  Finished  Recorded Date  Response ID  \\\n",
       "0                      NaN       NaN            NaN          NaN   \n",
       "21                  1082.0       1.0            NaN          NaN   \n",
       "75                  1328.0       1.0            NaN          NaN   \n",
       "109                  604.0       1.0            NaN          NaN   \n",
       "144                  833.0       1.0            NaN          NaN   \n",
       "208                 1022.0       1.0            NaN          NaN   \n",
       "247                  441.0       1.0            NaN          NaN   \n",
       "301                  752.0       1.0            NaN          NaN   \n",
       "336                  873.0       1.0            NaN          NaN   \n",
       "451                67607.0       1.0            NaN          NaN   \n",
       "464                  594.0       1.0            NaN          NaN   \n",
       "478                 7706.0       1.0            NaN          NaN   \n",
       "\n",
       "0    Recipient Last Name  ...  canning  aims  terrorist  \\\n",
       "0                    NaN  ...      NaN   NaN        NaN   \n",
       "21                   NaN  ...      0.0   0.0       -4.0   \n",
       "75                   NaN  ...      0.0   1.0       -4.0   \n",
       "109                  NaN  ...      0.0   0.0       -4.0   \n",
       "144                  NaN  ...      0.0   1.0       -4.0   \n",
       "208                  NaN  ...      0.0  -1.0       -4.0   \n",
       "247                  NaN  ...      0.0   1.0       -3.0   \n",
       "301                  NaN  ...     -1.0   0.0       -4.0   \n",
       "336                  NaN  ...     -2.0   1.0       -4.0   \n",
       "451                  NaN  ...     -2.0   2.0       -2.0   \n",
       "464                  NaN  ...      0.0   1.0       -4.0   \n",
       "478                  NaN  ...      0.0   0.0       -4.0   \n",
       "\n",
       "0    Please choose the option [+3].  \\\n",
       "0                               NaN   \n",
       "21                              3.0   \n",
       "75                              3.0   \n",
       "109                             3.0   \n",
       "144                             3.0   \n",
       "208                             3.0   \n",
       "247                             3.0   \n",
       "301                             3.0   \n",
       "336                             3.0   \n",
       "451                             3.0   \n",
       "464                             3.0   \n",
       "478                             3.0   \n",
       "\n",
       "0    Below are some questions for demographic purposes.  \\\n",
       "0                                                  NaN    \n",
       "21                                                 NaN    \n",
       "75                                                 NaN    \n",
       "109                                                NaN    \n",
       "144                                                NaN    \n",
       "208                                                NaN    \n",
       "247                                                NaN    \n",
       "301                                                NaN    \n",
       "336                                                NaN    \n",
       "451                                                NaN    \n",
       "464                                                NaN    \n",
       "478                                                NaN    \n",
       "\n",
       "0    How old are you? Please enter a number.  What year are you?  \\\n",
       "0                                        NaN                 NaN   \n",
       "21                                      18.0                 1.0   \n",
       "75                                      19.0                 2.0   \n",
       "109                                     19.0                 2.0   \n",
       "144                                     18.0                 1.0   \n",
       "208                                     19.0                 1.0   \n",
       "247                                     18.0                 1.0   \n",
       "301                                     19.0                 2.0   \n",
       "336                                     18.0                 1.0   \n",
       "451                                     19.0                 2.0   \n",
       "464                                     20.0                 3.0   \n",
       "478                                     18.0                 1.0   \n",
       "\n",
       "0    Are you a Psychology or Cognitive Science major?  \\\n",
       "0                                                 NaN   \n",
       "21                                                2.0   \n",
       "75                                                2.0   \n",
       "109                                               2.0   \n",
       "144                                               2.0   \n",
       "208                                               2.0   \n",
       "247                                               2.0   \n",
       "301                                               2.0   \n",
       "336                                               2.0   \n",
       "451                                               2.0   \n",
       "464                                               2.0   \n",
       "478                                               2.0   \n",
       "\n",
       "0    Have you learned about autism in any UVa courses presently or in the past?  \\\n",
       "0                                                  NaN                            \n",
       "21                                                 2.0                            \n",
       "75                                                 2.0                            \n",
       "109                                                2.0                            \n",
       "144                                                2.0                            \n",
       "208                                                2.0                            \n",
       "247                                                2.0                            \n",
       "301                                                1.0                            \n",
       "336                                                2.0                            \n",
       "451                                                2.0                            \n",
       "464                                                2.0                            \n",
       "478                                                2.0                            \n",
       "\n",
       "0    Debriefing Form\\nProtocol #: 6251: Sentiment Analysis \\nThank you for participating in this study! In this study, you rated several words for how\\nnegative or positive they were. We will calculate, for each word, the average rating and\\nuse those averages to be able to objectively quantify the \"sentiment\" of a piece of text.\\nOur particular interest is in assessing the average valence of the words used in sections of\\npopular college-level textbooks that describe autism. We will investigate how the valence\\nhas changed over time, whether textbooks in some sub-fields use more positive or\\nnegative words than others, and so on. This will allow us to understand and document\\nhow attitudes about autism are (or are not) changing in college-level textbooks. Sentiment analysis has been used for a number of purposes, including customer reviews\\nof products or services, social media analysis, and so on. It has also been used in the\\nhumanities to try to quantify the emotions or sentiments in stories and poems. \\nIf you feel especially concerned about any aspects of this study, please feel free to contact\\nProf. Jaswal at jaswal@virginia.edu about options for counseling. Alternatively, you\\ncould also phone the UVA Counseling and Psychological Services (434-243-5556) or the\\nMary D. Ainsworth Psychological Clinic in the psychology department (434-982-4737). \\nThank you for your participation in this study. \\nPlease contact the researchers on the study team listed below to: ● Obtain more information or if you have further questions about the study. ● Report an illness, injury, or other problem. ● Leave the study before it is finished. Vikram Jaswal, Ph.D.\\nProfessor of Psychology\\nDept. of Psychology PO Box 400400\\nUniversity of Virginia\\nCharlottesville, VA 22904-4400 Telephone: (434) 982-4709 Email: jaswal@virginia.edu \\nYou may also report a concern about a study or ask questions about your rights as a\\nresearch subject by contacting the Institutional Review Board listed below. Tonya R. Moon, Ph.D.\\nChair, Institutional Review Board for the Social and Behavioral Sciences One Morton Dr Suite 400\\nUniversity of Virginia, P.O. Box 800392\\nCharlottesville, VA 22908-0392 Telephone: (434) 924-5999 Email: irbsbshelp@virginia.edu Website: https://research.virginia.edu/irb-sbs Website for Research Participants: https://research.virginia.edu/research-participants \\nUVA IRB-SBS # 6251 \\nAdditional Reading: To learn more general information about sentiment analysis, you can visit:\\nhttps://aws.amazon.com/what-is/sentiment-analysis/ Wankhade, M., Rao, A.C.S. & Kulkarni, C. (2022). A survey on sentiment analysis\\nmethods, applications, and challenges. Artificial Intelligence Review, 55, 5731–5780\\n(2022). https://doi.org/10.1007/s10462-022-10144-1  \n",
       "0                                                  NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "21                                                 NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "75                                                 NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "109                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "144                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "208                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "247                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "301                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "336                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "451                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "464                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "478                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "\n",
       "[12 rows x 245 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data frame into mini dataframes representing each survey\n",
    "\n",
    "# 1: QID8457 -- QID8664\n",
    "beginning = df.loc[:, \"StartDate\":\"QID12\"] # Study agreement questions and \"golden item\" questions\n",
    "# print(beginning)\n",
    "end = df.loc[:, \"Q10051\":] # Demographics\n",
    "# print(end)\n",
    "# example = (df.loc[:,\"QID8456\":\"QID8664\"]) # 209 columns of words and valences\n",
    "# print(example)\n",
    "# 2: QID1142 -- QID1349\n",
    "# 3: (etc.)\n",
    "\n",
    "# df_example = [beginning, example, end]\n",
    "# df_example = pd.concat(df_example, axis=1) \n",
    "# print(df_example)\n",
    "\n",
    "# Create a dictionary holding all the surveys\n",
    "dict_of_dfs = {}\n",
    "# dict_of_questions = {}\n",
    "questions = df.loc[:,\"QID8456\":\"QID10834\"]\n",
    "# questions = df.loc[:, \"QID2\":\"QID10834\"]\n",
    "for i in range(48):\n",
    "    name_of_df = \"df_\" + str(i)\n",
    "    questions_specific = questions.iloc[:, (i*209):((i+1)*209)] # Get only the questions of that survey\n",
    "    \n",
    "    \n",
    "    df_entry = [beginning, questions_specific, end] # But include the study agreements and demographics\n",
    "    df_entry = pd.concat(df_entry, axis=1)\n",
    "    df_entry = df_entry.dropna(thresh=209,axis=0) # Only include people who filled out that particular survey\n",
    "    # Make the first row the columns\n",
    "    df_entry.columns = df_entry.iloc[0]\n",
    "    df_entry = df_entry.apply(pd.to_numeric, errors='coerce', downcast='integer')\n",
    "    \n",
    "    # Get the questions only\n",
    "#     practice_questions = df_entry.iloc[:, \"QID3\":\"QID12\"]\n",
    "#     questions_full = [practice_questions, questions_specific]\n",
    "#     questions_full = pd.concat(questions_full, axis=1)\n",
    "    \n",
    "    \n",
    "    dict_of_dfs[name_of_df] = df_entry # Add to dictionary\n",
    "#     dict_of_questions[name_of_df] = questions_full\n",
    "\n",
    "# Example: Survey #8 (ninth survey)\n",
    "dict_of_dfs[\"df_8\"]\n",
    "# dict_of_questions[\"df_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf9b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 9, 11, 10, 9, 11, 10, 11, 11, 11, 9, 9, 11, 10, 10, 11, 10, 11, 11, 10, 9, 11, 11, 10, 10, 10, 11, 9, 10, 10, 11, 10, 10, 11, 9, 11, 11, 10, 12, 12, 10, 12, 11, 11, 11, 11, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "# Exclude people who did not answer \"Please choose option [x]\" questions correctly\n",
    "\n",
    "# In order:\n",
    "# \"Please choose the option [+2].\"\n",
    "# \"Please choose the option [-1].\"\n",
    "# \"Please choose the option [0].\"\n",
    "# \"Please choose the option [+3].\"\n",
    "non_excluded = []\n",
    "for key in dict_of_dfs.keys():\n",
    "#     print(\"Change below\")\n",
    "    dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "    dataframe = dataframe.loc[(dataframe[\"Please choose the option [+2].\"] == 2) & (dataframe[\"Please choose the option [-1].\"] == -1) & (dataframe[\"Please choose the option [0].\"] == 0) & (dataframe[\"Please choose the option [+3].\"] == 3)]\n",
    "    dict_of_dfs[key] = dataframe\n",
    "    non_excluded.append(len(dataframe))\n",
    "#     print(\"------\")\n",
    "\n",
    "print(non_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8245bd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Start Date  End Date  Response Type  IP Address  Progress  \\\n",
      "15          NaN       NaN            0.0         NaN     100.0   \n",
      "69          NaN       NaN            0.0         NaN     100.0   \n",
      "159         NaN       NaN            0.0         NaN     100.0   \n",
      "188         NaN       NaN            0.0         NaN     100.0   \n",
      "259         NaN       NaN            0.0         NaN     100.0   \n",
      "289         NaN       NaN            0.0         NaN     100.0   \n",
      "416         NaN       NaN            0.0         NaN     100.0   \n",
      "440         NaN       NaN            0.0         NaN     100.0   \n",
      "475         NaN       NaN            0.0         NaN     100.0   \n",
      "\n",
      "0    Duration (in seconds)  Finished  Recorded Date  Response ID  \\\n",
      "15                   478.0       1.0            NaN          NaN   \n",
      "69                   643.0       1.0            NaN          NaN   \n",
      "159                  468.0       1.0            NaN          NaN   \n",
      "188                 3127.0       1.0            NaN          NaN   \n",
      "259                  715.0       1.0            NaN          NaN   \n",
      "289                  764.0       1.0            NaN          NaN   \n",
      "416                  826.0       1.0            NaN          NaN   \n",
      "440                  457.0       1.0            NaN          NaN   \n",
      "475                 1335.0       1.0            NaN          NaN   \n",
      "\n",
      "0    Recipient Last Name  ...  rub  necessity  terrorist  \\\n",
      "15                   NaN  ...  0.0        0.0        0.0   \n",
      "69                   NaN  ...  1.0        0.0       -4.0   \n",
      "159                  NaN  ...  0.0       -1.0       -4.0   \n",
      "188                  NaN  ...  0.0        1.0       -3.0   \n",
      "259                  NaN  ...  1.0        3.0       -4.0   \n",
      "289                  NaN  ...  4.0        4.0       -4.0   \n",
      "416                  NaN  ...  0.0        1.0       -4.0   \n",
      "440                  NaN  ...  0.0        0.0       -3.0   \n",
      "475                  NaN  ...  0.0        0.0       -4.0   \n",
      "\n",
      "0    Please choose the option [+3].  \\\n",
      "15                              3.0   \n",
      "69                              3.0   \n",
      "159                             3.0   \n",
      "188                             3.0   \n",
      "259                             3.0   \n",
      "289                             3.0   \n",
      "416                             3.0   \n",
      "440                             3.0   \n",
      "475                             3.0   \n",
      "\n",
      "0    Below are some questions for demographic purposes.  \\\n",
      "15                                                 NaN    \n",
      "69                                                 NaN    \n",
      "159                                                NaN    \n",
      "188                                                NaN    \n",
      "259                                                NaN    \n",
      "289                                                NaN    \n",
      "416                                                NaN    \n",
      "440                                                NaN    \n",
      "475                                                NaN    \n",
      "\n",
      "0    How old are you? Please enter a number.  What year are you?  \\\n",
      "15                                      18.0                 1.0   \n",
      "69                                      18.0                 1.0   \n",
      "159                                     18.0                 1.0   \n",
      "188                                     19.0                 2.0   \n",
      "259                                     18.0                 1.0   \n",
      "289                                     20.0                 3.0   \n",
      "416                                     19.0                 1.0   \n",
      "440                                     18.0                 3.0   \n",
      "475                                     20.0                 2.0   \n",
      "\n",
      "0    Are you a Psychology or Cognitive Science major?  \\\n",
      "15                                                2.0   \n",
      "69                                                2.0   \n",
      "159                                               2.0   \n",
      "188                                               2.0   \n",
      "259                                               2.0   \n",
      "289                                               2.0   \n",
      "416                                               2.0   \n",
      "440                                               2.0   \n",
      "475                                               1.0   \n",
      "\n",
      "0    Have you learned about autism in any UVa courses presently or in the past?  \\\n",
      "15                                                 2.0                            \n",
      "69                                                 2.0                            \n",
      "159                                                2.0                            \n",
      "188                                                2.0                            \n",
      "259                                                2.0                            \n",
      "289                                                2.0                            \n",
      "416                                                2.0                            \n",
      "440                                                1.0                            \n",
      "475                                                2.0                            \n",
      "\n",
      "0    Debriefing Form\\nProtocol #: 6251: Sentiment Analysis \\nThank you for participating in this study! In this study, you rated several words for how\\nnegative or positive they were. We will calculate, for each word, the average rating and\\nuse those averages to be able to objectively quantify the \"sentiment\" of a piece of text.\\nOur particular interest is in assessing the average valence of the words used in sections of\\npopular college-level textbooks that describe autism. We will investigate how the valence\\nhas changed over time, whether textbooks in some sub-fields use more positive or\\nnegative words than others, and so on. This will allow us to understand and document\\nhow attitudes about autism are (or are not) changing in college-level textbooks. Sentiment analysis has been used for a number of purposes, including customer reviews\\nof products or services, social media analysis, and so on. It has also been used in the\\nhumanities to try to quantify the emotions or sentiments in stories and poems. \\nIf you feel especially concerned about any aspects of this study, please feel free to contact\\nProf. Jaswal at jaswal@virginia.edu about options for counseling. Alternatively, you\\ncould also phone the UVA Counseling and Psychological Services (434-243-5556) or the\\nMary D. Ainsworth Psychological Clinic in the psychology department (434-982-4737). \\nThank you for your participation in this study. \\nPlease contact the researchers on the study team listed below to: ● Obtain more information or if you have further questions about the study. ● Report an illness, injury, or other problem. ● Leave the study before it is finished. Vikram Jaswal, Ph.D.\\nProfessor of Psychology\\nDept. of Psychology PO Box 400400\\nUniversity of Virginia\\nCharlottesville, VA 22904-4400 Telephone: (434) 982-4709 Email: jaswal@virginia.edu \\nYou may also report a concern about a study or ask questions about your rights as a\\nresearch subject by contacting the Institutional Review Board listed below. Tonya R. Moon, Ph.D.\\nChair, Institutional Review Board for the Social and Behavioral Sciences One Morton Dr Suite 400\\nUniversity of Virginia, P.O. Box 800392\\nCharlottesville, VA 22908-0392 Telephone: (434) 924-5999 Email: irbsbshelp@virginia.edu Website: https://research.virginia.edu/irb-sbs Website for Research Participants: https://research.virginia.edu/research-participants \\nUVA IRB-SBS # 6251 \\nAdditional Reading: To learn more general information about sentiment analysis, you can visit:\\nhttps://aws.amazon.com/what-is/sentiment-analysis/ Wankhade, M., Rao, A.C.S. & Kulkarni, C. (2022). A survey on sentiment analysis\\nmethods, applications, and challenges. Artificial Intelligence Review, 55, 5731–5780\\n(2022). https://doi.org/10.1007/s10462-022-10144-1  \n",
      "15                                                 NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "69                                                 NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "159                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "188                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "259                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "289                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "416                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "440                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "475                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      "\n",
      "[9 rows x 245 columns]\n"
     ]
    }
   ],
   "source": [
    "# Keep participants who got > 80% golden items within +/- 2\n",
    "\n",
    "how_many_people_correct = []\n",
    "eighty_correct_2 = []\n",
    "for key in dict_of_dfs.keys():\n",
    "#     print(\"Change below\")\n",
    "    dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "\n",
    "    dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "    counter_people = False\n",
    "    for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "        # Give a point if they get the ideal solution\n",
    "        counter = 0\n",
    "        if row[\"love\"] >= 1:\n",
    "            counter += 1\n",
    "        if row[\"charming\"] >= 1:\n",
    "            counter += 1\n",
    "        if row[\"proud\"] >= 0:\n",
    "            counter += 1\n",
    "        if row[\"safe\"] >= 0:\n",
    "            counter += 1\n",
    "        if row[\"resolvable\"] >= -1 and row[\"resolvable\"] <= 3:\n",
    "            counter += 1\n",
    "        if row[\"prepared\"] >= -1 and row[\"prepared\"] <= 3:\n",
    "            counter += 1\n",
    "        if row[\"reach\"] >= -2 and row[\"reach\"] <= 2:\n",
    "            counter += 1\n",
    "        if row[\"backed\"] >= -2 and row[\"backed\"] <= 2:\n",
    "            counter += 1\n",
    "        if row[\"shy\"] >= -3 and row[\"shy\"] <= 1:\n",
    "            counter += 1\n",
    "        if row[\"stutter\"] >= -3 and row[\"stutter\"] <= 1:\n",
    "            counter += 1\n",
    "        if row[\"depriving\"] <= 0:\n",
    "            counter += 1\n",
    "        if row[\"ungrateful\"] <= 0:\n",
    "            counter += 1\n",
    "        if row[\"cruelness\"] <= -1:\n",
    "            counter += 1\n",
    "        if row[\"repulse\"] <= -1:\n",
    "            counter += 1\n",
    "        if row[\"slavery\"] <= -2:\n",
    "            counter += 1\n",
    "        if row[\"terrorist\"] <= -2:\n",
    "            counter += 1\n",
    "#         print(counter)\n",
    "        if counter / 16 >= 0.8: # Keep the person if they got >80% correct +/- 2\n",
    "            counter_people = True\n",
    "    \n",
    "        if not counter_people: # If they didn't do well, remove them\n",
    "            dataframe.drop([index])\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "#     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "#     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "    dict_of_dfs[key] = dataframe\n",
    "#     print(\"counter_people: \", counter_people)\n",
    "#     how_many_people_correct.append(counter_people)\n",
    "#     eighty_correct_2.append(counter_people)\n",
    "# print(eighty_correct_2)\n",
    "# print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# print(min(how_many_people_correct))\n",
    "\n",
    "print(dict_of_dfs[\"df_27\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afdf735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    stutter  depriving  charming  backed  resolvable  proud  shy  repulse  \\\n",
      "58      -3.0       -2.0       3.0     0.0         2.0    4.0 -1.0     -3.0   \n",
      "113     -1.0       -3.0       3.0     2.0         1.0    1.0 -2.0     -4.0   \n",
      "174     -2.0       -3.0       3.0    -1.0         1.0    3.0 -1.0     -4.0   \n",
      "215     -2.0       -4.0       3.0     0.0         2.0    3.0 -1.0     -3.0   \n",
      "256     -1.0       -3.0       3.0     0.0         0.0    3.0  0.0     -3.0   \n",
      "282     -2.0       -3.0       3.0    -2.0         1.0    3.0 -1.0     -3.0   \n",
      "347     -1.0       -2.0       4.0     0.0         2.0    4.0  0.0      0.0   \n",
      "377     -1.0       -1.0       2.0    -1.0         1.0    3.0 -1.0     -3.0   \n",
      "459     -3.0       -1.0       3.0     2.0         1.0    4.0 -1.0     -4.0   \n",
      "473      2.0       -1.0       3.0     0.0         4.0    4.0  0.0      0.0   \n",
      "\n",
      "0    ungrateful  slavery  ...  venter  army  anticipatory  writer  jointly  \\\n",
      "58         -3.0     -4.0  ...     0.0   1.0           1.0     1.0      1.0   \n",
      "113        -3.0     -4.0  ...     0.0  -1.0           1.0     1.0      2.0   \n",
      "174        -2.0     -4.0  ...    -1.0   0.0          -1.0     0.0      1.0   \n",
      "215        -4.0     -4.0  ...    -2.0   0.0           1.0     0.0      0.0   \n",
      "256        -2.0     -3.0  ...     0.0   0.0          -1.0     0.0      0.0   \n",
      "282        -4.0     -4.0  ...     1.0  -1.0           1.0    -1.0      1.0   \n",
      "347        -4.0     -3.0  ...     0.0  -2.0           0.0     1.0      1.0   \n",
      "377        -3.0     -4.0  ...     0.0   0.0           0.0     0.0      0.0   \n",
      "459        -3.0     -4.0  ...     0.0   0.0           0.0     1.0      1.0   \n",
      "473        -3.0     -4.0  ...     1.0  -4.0           0.0     0.0      0.0   \n",
      "\n",
      "0    finer  rudimentary  barking  incidences  terrorist  \n",
      "58     1.0          0.0     -1.0        -2.0       -4.0  \n",
      "113    1.0         -1.0     -2.0        -1.0       -4.0  \n",
      "174    0.0          0.0     -1.0        -1.0       -4.0  \n",
      "215    2.0          1.0     -2.0         0.0       -4.0  \n",
      "256    0.0          0.0      0.0        -2.0       -4.0  \n",
      "282   -1.0          1.0     -1.0        -1.0       -4.0  \n",
      "347    0.0          0.0     -1.0        -1.0       -4.0  \n",
      "377    0.0          0.0      0.0         0.0       -2.0  \n",
      "459    2.0         -2.0     -1.0        -2.0       -4.0  \n",
      "473    0.0          1.0      1.0         1.0       -3.0  \n",
      "\n",
      "[10 rows x 214 columns]\n"
     ]
    }
   ],
   "source": [
    "# Format dataframes to get only words for dictionary\n",
    "\n",
    "dictionary = pd.DataFrame()\n",
    "\n",
    "for key in dict_of_dfs.keys():\n",
    "\n",
    "    dataframe = dict_of_dfs[key]\n",
    "    \n",
    "    # Get the questions only\n",
    "    \n",
    "    dataframe = dataframe.loc[:, \"stutter\":\"Below are some questions for demographic purposes.\"]\n",
    "    \n",
    "    dataframe = dataframe.loc[:,~dataframe.columns.str.endswith('.')]\n",
    "\n",
    "    dict_of_dfs[key] = dataframe\n",
    "    \n",
    "    \n",
    "\n",
    "print(dict_of_dfs[\"df_32\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942222b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>mean</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stutter</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>0.862439</td>\n",
       "      <td>[-2.0, 0.0, -3.0, -2.0, -1.0, -1.0, -2.0, -3.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depriving</td>\n",
       "      <td>-2.545455</td>\n",
       "      <td>1.075651</td>\n",
       "      <td>[-3.0, 0.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charming</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>0.481046</td>\n",
       "      <td>[3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>backed</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.987525</td>\n",
       "      <td>[2.0, 0.0, 0.0, 0.0, 2.0, 2.0, -1.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolvable</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>1.336085</td>\n",
       "      <td>[-1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, -1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>develop</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>0.771389</td>\n",
       "      <td>[2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>learn</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>1.113404</td>\n",
       "      <td>[3.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>resiliency</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>1.266217</td>\n",
       "      <td>[4.0, 2.0, 0.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9511</th>\n",
       "      <td>weights</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>0.935966</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 1.0, -2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9512</th>\n",
       "      <td>impairments</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>1.285649</td>\n",
       "      <td>[-1.0, 0.0, 0.0, -3.0, -3.0, -2.0, -3.0, -1.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9513 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      mean   std_dev  \\\n",
       "0         stutter -1.727273  0.862439   \n",
       "1       depriving -2.545455  1.075651   \n",
       "2        charming  2.636364  0.481046   \n",
       "3          backed  0.545455  0.987525   \n",
       "4      resolvable  1.181818  1.336085   \n",
       "...           ...       ...       ...   \n",
       "9508      develop  1.363636  0.771389   \n",
       "9509        learn  2.181818  1.113404   \n",
       "9510   resiliency  2.818182  1.266217   \n",
       "9511      weights -0.181818  0.935966   \n",
       "9512  impairments -1.727273  1.285649   \n",
       "\n",
       "                                             raw_scores  \n",
       "0     [-2.0, 0.0, -3.0, -2.0, -1.0, -1.0, -2.0, -3.0...  \n",
       "1     [-3.0, 0.0, -4.0, -3.0, -3.0, -3.0, -3.0, -3.0...  \n",
       "2     [3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, ...  \n",
       "3     [2.0, 0.0, 0.0, 0.0, 2.0, 2.0, -1.0, 0.0, 0.0,...  \n",
       "4     [-1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, -1.0...  \n",
       "...                                                 ...  \n",
       "9508  [2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, ...  \n",
       "9509  [3.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, ...  \n",
       "9510  [4.0, 2.0, 0.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, ...  \n",
       "9511  [0.0, 0.0, 0.0, 0.0, -2.0, 0.0, 0.0, 1.0, -2.0...  \n",
       "9512  [-1.0, 0.0, 0.0, -3.0, -3.0, -2.0, -3.0, -1.0,...  \n",
       "\n",
       "[9513 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dictionary (in dataframe form)\n",
    "# Format: word (tab) mean (tab) standard deviation (tab) raw scores (as a bracketed list)\n",
    "\n",
    "all_words = []\n",
    "means = []\n",
    "stdevs = []\n",
    "raw_scores = []\n",
    "for key in dict_of_dfs.keys():\n",
    "\n",
    "    dataframe = dict_of_dfs[key]\n",
    "    \n",
    "    # Make a column for the words\n",
    "    for word in dataframe.columns:\n",
    "        if word not in all_words: # Only include the \"golden items\" for the first survey, to avoid too much data for those words\n",
    "            all_words.append(word)\n",
    "            scores = dataframe[word].dropna().to_list() # Get the scores as a list\n",
    "            means.append(np.mean(scores)) # Get the means\n",
    "            stdevs.append(np.std(scores)) # Get the standard deviations\n",
    "            raw_scores.append(scores) # Get the scores as a list but put them into a bigger list\n",
    "            \n",
    "        \n",
    "# Create the dataframe            \n",
    "dictionary[\"word\"] = all_words\n",
    "dictionary[\"mean\"] = means\n",
    "dictionary[\"std_dev\"] = stdevs\n",
    "dictionary[\"raw_scores\"] = raw_scores\n",
    "\n",
    "dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d321c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dir = r\"C:\\Users\\maksi\\Documents\\UVA\\Research\\DMP\\Dictionaries\"\n",
    "\n",
    "os.chdir(dict_dir)\n",
    "dictionary.to_csv('final_dictionary.txt', header=None, index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f1265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude people who did not get within +/- 0 of all of the \"golden items\" (Not many got all of them within +/- 1...)\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# golden_items_correct = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "#     original_number_of_people = len(dataframe)\n",
    "# #     print(len(dataframe))\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "#     dataframe = dataframe[dataframe[\"love\"] == 3] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"charming\"] == 3)] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"proud\"] == 2)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"safe\"] == 2)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"resolvable\"] == 1)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"prepared\"] == 1)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"reach\"] == 0)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"backed\"] == 0)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"shy\"] == -1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"stutter\"] == -1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"depriving\"] == -2)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] == -2)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"cruelness\"] == -3)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"repulse\"] == -3)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"slavery\"] == -4)] # -4\n",
    "#     dataframe = dataframe.loc[(dataframe[\"terrorist\"] == -4)] # -4\n",
    "\n",
    "#     final_number_of_people = len(dataframe)\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(len(dataframe))\n",
    "#     how_many_people_correct.append(len(dataframe))\n",
    "    \n",
    "#     golden_items_correct.append(final_number_of_people/original_number_of_people)\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))\n",
    "# print(golden_items_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c70413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude people who did not get within +/- 1 of all of the \"golden items\" (Not many got all of them within +/- 1...)\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# golden_items_correct_1 = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "#     original_number_of_people = len(dataframe)\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "#     dataframe = dataframe[dataframe[\"love\"] >= 2] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 2)] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 1) & (dataframe[\"proud\"] <= 3)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 1) & (dataframe[\"safe\"] <= 3)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= 0) & (dataframe[\"resolvable\"] <= 2)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= 0) & (dataframe[\"prepared\"] <= 2)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -1) & (dataframe[\"reach\"] <= 1)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -1) & (dataframe[\"backed\"] <= 1)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -2) & (dataframe[\"shy\"] <= 0)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -2) & (dataframe[\"stutter\"] <= 0)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -3) & (dataframe[\"depriving\"] <= -1)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -3) & (dataframe[\"ungrateful\"] <= -1)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -2)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -2)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -3)] # -4\n",
    "#     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -3)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(len(dataframe))\n",
    "#     how_many_people_correct.append(len(dataframe))\n",
    "#     final_number_of_people = len(dataframe)\n",
    "\n",
    "#     golden_items_correct_1.append(final_number_of_people/original_number_of_people)\n",
    "\n",
    "\n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))\n",
    "# print(golden_items_correct_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9fa0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude people who did not get within +/- 2 of all of the \"golden items\" (Not many got all of them within +/- 1...)\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# golden_items_correct_2 = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "#     original_number_of_people = len(dataframe)\n",
    "\n",
    "# # titanic[titanic[\"Age\"] > 35]\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "#     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "#     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(len(dataframe))\n",
    "#     how_many_people_correct.append(len(dataframe))\n",
    "#     final_number_of_people = len(dataframe)\n",
    "\n",
    "#     golden_items_correct_2.append(final_number_of_people/original_number_of_people)\n",
    "    \n",
    "\n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))\n",
    "# print(golden_items_correct_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b15980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many golden items did people get correct on average?\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# all_correct = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     participants = []\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] == 3:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] == 3:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] == 2:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] == 2:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] == 1:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] == 1:\n",
    "#             counter += 1\n",
    "#         if row[\"reach\"] == 0:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] == 0:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] == -1:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] == -1:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] == -2:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] == -2:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] == -3:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] == -3:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] == -4:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] == -4:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "# #         if counter / 16 >= 0.8:\n",
    "# #             counter_people += 1\n",
    "    \n",
    "#         correct_number = counter / 16\n",
    "#         participants.append(correct_number)\n",
    "        \n",
    "#     all_correct.append(sum(participants)/len(participants))\n",
    "    \n",
    "# print(all_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10de724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ditto for only participants who got golden items within +/- 1\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# all_correct_1 = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] >= 1 and row[\"proud\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 1 and row[\"safe\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= 0 and row[\"resolvable\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= 0 and row[\"prepared\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"reach\"] >= -1 and row[\"reach\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] >= -1 and row[\"backed\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] >= -2 and row[\"shy\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] >= -2 and row[\"stutter\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= -1 and row[\"depriving\"] >= -3:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= -1 and row[\"ungrateful\"] >= -3:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= -3:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= -3:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         correct_number = counter / 16\n",
    "#         participants.append(correct_number)\n",
    "        \n",
    "#     all_correct_1.append(sum(participants)/len(participants))\n",
    "    \n",
    "# print(all_correct_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b8f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ditto for only participants who got golden items within +/- 2?\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# all_correct_2 = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= -1 and row[\"resolvable\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= -1 and row[\"prepared\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"reach\"] >= -2 and row[\"reach\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] >= -2 and row[\"backed\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] >= -3 and row[\"shy\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] >= -3 and row[\"stutter\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= -1:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= -1:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= -2:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         correct_number = counter / 16\n",
    "#         participants.append(correct_number)\n",
    "        \n",
    "#     all_correct_2.append(sum(participants)/len(participants))\n",
    "    \n",
    "# print(all_correct_2)\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a73548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exclude people who did not get 80% of the \"golden items\" \n",
    "\n",
    "# how_many_people_correct = []\n",
    "# eighty_correct = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] == 3:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] == 3:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] == 2:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] == 2:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] == 1:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] == 1:\n",
    "#             counter += 1\n",
    "#         if row[\"reach\"] == 0:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] == 0:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] == -1:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] == -1:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] == -2:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] == -2:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] == -3:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] == -3:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] == -4:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] == -4:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         if counter / 16 >= 0.8:\n",
    "#             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "#     how_many_people_correct.append(counter_people)\n",
    "#     eighty_correct.append(counter_people)\n",
    "# print(eighty_correct)\n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aed179a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ditto for only participants who got > 80% golden items within +/- 1\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# eighty_correct_1 = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 2:\n",
    "#             counter += 1\n",
    "# #         if row[\"proud\"] >= 1 and row[\"proud\"] <= 3:\n",
    "# #             counter += 1\n",
    "#         if row[\"safe\"] >= 1 and row[\"safe\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= 0 and row[\"resolvable\"] <= 2:\n",
    "#             counter += 1\n",
    "# #         if row[\"prepared\"] >= 0 and row[\"prepared\"] <= 2:\n",
    "# #             counter += 1\n",
    "#         if row[\"reach\"] >= -1 and row[\"reach\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] >= -1 and row[\"backed\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] >= -2 and row[\"shy\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] >= -2 and row[\"stutter\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= -1 and row[\"depriving\"] >= -3:\n",
    "#             counter += 1\n",
    "# #         if row[\"ungrateful\"] <= -1 and row[\"ungrateful\"] >= -3:\n",
    "# #             counter += 1\n",
    "#         if row[\"cruelness\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= -3:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= -3:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         if counter / 13 >= 0.8:\n",
    "#             counter_people += 1\n",
    "\n",
    "#     how_many_people_correct.append(counter_people)\n",
    "#     eighty_correct_1.append(counter_people)\n",
    "# print(eighty_correct_1)\n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81f6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ditto for only participants who got > 80% golden items within +/- 2?\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# eighty_correct_2 = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= -1 and row[\"resolvable\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= -1 and row[\"prepared\"] <= 3:\n",
    "#             counter += 1\n",
    "#         if row[\"reach\"] >= -2 and row[\"reach\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"backed\"] >= -2 and row[\"backed\"] <= 2:\n",
    "#             counter += 1\n",
    "#         if row[\"shy\"] >= -3 and row[\"shy\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] >= -3 and row[\"stutter\"] <= 1:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= -1:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= -1:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= -2:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= -2:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         if counter / 16 >= 0.8:\n",
    "#             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "#     how_many_people_correct.append(counter_people)\n",
    "#     eighty_correct_2.append(counter_people)\n",
    "# print(eighty_correct_2)\n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "824a64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many golden items did people get correct valence on average?\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# all_correct_valence = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     participants = []\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"]>= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= 0:\n",
    "#             counter += 1\n",
    "# #         if row[\"reach\"] == 0:\n",
    "# #             counter += 1\n",
    "# #         if row[\"backed\"] == 0:\n",
    "# #             counter += 1\n",
    "#         if row[\"shy\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= 0:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "# #         if counter / 16 >= 0.8:\n",
    "# #             counter_people += 1\n",
    "    \n",
    "#         correct_number = counter / 16\n",
    "#         participants.append(correct_number)\n",
    "        \n",
    "#     all_correct_valence.append(sum(participants)/len(participants))\n",
    "    \n",
    "# print(all_correct_valence)\n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "# #     eighty_correct.append(counter_people / len(dataframe))\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "606255cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many golden items did people get correct valence on average?\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# all_correct_valence_participants = []\n",
    "# participants = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "# #     participants = []\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"]>= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= 0:\n",
    "#             counter += 1\n",
    "# #         if row[\"reach\"] == 0:\n",
    "# #             counter += 1\n",
    "# #         if row[\"backed\"] == 0:\n",
    "# #             counter += 1\n",
    "#         if row[\"shy\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= 0:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         if counter / 16 == 1:\n",
    "#             counter_people += 1\n",
    "    \n",
    "# #         correct_number = counter / 16\n",
    "#     participants.append(counter_people)\n",
    "# #         participants.append(correct_number)\n",
    "        \n",
    "# #     all_correct_valence_participants.append(sum(participants)/len(participants))\n",
    "    \n",
    "# print(participants)\n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "# #     eighty_correct.append(counter_people / len(dataframe))\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb84af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many of the 10 were they ideal? \n",
    "\n",
    "# how_many_people_correct = []\n",
    "# love_c = []\n",
    "# charming_c = []\n",
    "# proud_c = []\n",
    "# safe_c = []\n",
    "# resolvable_c = []\n",
    "# prepared_c = []\n",
    "# reach_c = []\n",
    "# backed_c = []\n",
    "# shy_c = []\n",
    "# stutter_c = []\n",
    "# depriving_c = []\n",
    "# ungrateful_c = []\n",
    "# repulse_c = []\n",
    "# cruelness_c = []\n",
    "# slavery_c = []\n",
    "# terrorist_c = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "# #     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     # Scores for each item\n",
    "#     love = 0\n",
    "#     charming = 0\n",
    "#     proud = 0\n",
    "#     safe = 0\n",
    "#     resolvable = 0\n",
    "#     prepared = 0\n",
    "#     reach = 0\n",
    "#     backed = 0\n",
    "#     shy = 0\n",
    "#     stutter = 0\n",
    "#     depriving = 0\n",
    "#     ungrateful = 0\n",
    "#     repulse = 0\n",
    "#     cruelness = 0\n",
    "#     slavery = 0\n",
    "#     terrorist = 0\n",
    "    \n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] == 3:\n",
    "#             love += 1\n",
    "#         if row[\"charming\"] == 3:\n",
    "#             charming += 1\n",
    "#         if row[\"proud\"] == 2:\n",
    "#             proud += 1\n",
    "#         if row[\"safe\"] == 2:\n",
    "#             safe += 1\n",
    "#         if row[\"resolvable\"] == 1:\n",
    "#             resolvable += 1\n",
    "#         if row[\"prepared\"] == 1:\n",
    "#             prepared += 1\n",
    "#         if row[\"reach\"] == 0:\n",
    "#             reach += 1\n",
    "#         if row[\"backed\"] == 0:\n",
    "#             backed += 1\n",
    "#         if row[\"shy\"] == -1:\n",
    "#             shy += 1\n",
    "#         if row[\"stutter\"] == -1:\n",
    "#             stutter += 1\n",
    "#         if row[\"depriving\"] == -2:\n",
    "#             depriving += 1\n",
    "#         if row[\"ungrateful\"] == -2:\n",
    "#             ungrateful += 1\n",
    "#         if row[\"cruelness\"] == -3:\n",
    "#             cruelness += 1\n",
    "#         if row[\"repulse\"] == -3:\n",
    "#             repulse += 1\n",
    "#         if row[\"slavery\"] == -4:\n",
    "#             slavery += 1\n",
    "#         if row[\"terrorist\"] == -4:\n",
    "#             terrorist += 1\n",
    "# #         print(counter)\n",
    "# #         if counter / 16 >= 0.8:\n",
    "# #             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "# #     print(\"love: \", love)\n",
    "#     love_c.append(love / len(dataframe))\n",
    "# #     print(\"charming: \", charming)\n",
    "#     charming_c.append(charming / len(dataframe))\n",
    "# #     print(\"proud: \", proud)\n",
    "#     proud_c.append(proud / len(dataframe))\n",
    "# #     print(\"safe: \", safe)\n",
    "#     safe_c.append(safe / len(dataframe))\n",
    "# #     print(\"resolvable: \", resolvable)\n",
    "#     resolvable_c.append(resolvable / len(dataframe))\n",
    "# #     print(\"prepared: \", prepared)\n",
    "#     prepared_c.append(prepared / len(dataframe))\n",
    "# #     print(\"reach: \", reach)\n",
    "#     reach_c.append(reach / len(dataframe))\n",
    "# #     print(\"backed: \", backed)\n",
    "#     backed_c.append(backed / len(dataframe))\n",
    "# #     print(\"shy: \", shy)\n",
    "#     shy_c.append(shy / len(dataframe))\n",
    "# #     print(\"stutter: \", stutter)\n",
    "#     stutter_c.append(stutter / len(dataframe))\n",
    "# #     print(\"depriving: \", depriving)\n",
    "#     depriving_c.append(depriving / len(dataframe))\n",
    "# #     print(\"ungrateful: \", ungrateful)\n",
    "#     ungrateful_c.append(ungrateful / len(dataframe))\n",
    "# #     print(\"cruelness: \", cruelness)\n",
    "#     cruelness_c.append(cruelness / len(dataframe))\n",
    "# #     print(\"repulse: \", repulse)\n",
    "#     repulse_c.append(repulse / len(dataframe))\n",
    "# #     print(\"slavery: \", slavery)\n",
    "#     slavery_c.append(slavery / len(dataframe))\n",
    "# #     print(\"terrorist: \", terrorist)\n",
    "#     terrorist_c.append(terrorist / len(dataframe))\n",
    "    \n",
    "# print(\"love: \", sum(love_c) / len(love_c))\n",
    "# print(\"charming: \", sum(charming_c) / len(charming_c))\n",
    "# print(\"proud: \", sum(proud_c) / len(proud_c))\n",
    "# print(\"safe: \", sum(safe_c) / len(safe_c))\n",
    "# print(\"resolvable: \", sum(resolvable_c) / len(resolvable_c))\n",
    "# print(\"prepared: \", sum(prepared_c) / len(prepared_c))\n",
    "# print(\"reach: \", sum(reach_c) / len(reach_c))\n",
    "# print(\"backed: \", sum(backed_c) / len(backed_c))\n",
    "# print(\"shy: \", sum(shy_c) / len(shy_c))\n",
    "# print(\"stutter: \", sum(stutter_c) / len(stutter_c))\n",
    "# print(\"depriving: \", sum(depriving_c) / len(depriving_c))\n",
    "# print(\"ungrateful: \", sum(ungrateful_c) / len(ungrateful_c))\n",
    "# print(\"cruelness: \", sum(cruelness_c) / len(cruelness_c))\n",
    "# print(\"repulse: \", sum(repulse_c) / len(repulse_c))\n",
    "# print(\"slavery: \", sum(slavery_c) / len(slavery_c))\n",
    "# print(\"terrorist: \", sum(terrorist_c) / len(terrorist_c))\n",
    "\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb52e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many of the 10 were they within +/- 1? \n",
    "\n",
    "# how_many_people_correct = []\n",
    "# love_c = []\n",
    "# charming_c = []\n",
    "# proud_c = []\n",
    "# safe_c = []\n",
    "# resolvable_c = []\n",
    "# prepared_c = []\n",
    "# reach_c = []\n",
    "# backed_c = []\n",
    "# shy_c = []\n",
    "# stutter_c = []\n",
    "# depriving_c = []\n",
    "# ungrateful_c = []\n",
    "# repulse_c = []\n",
    "# cruelness_c = []\n",
    "# slavery_c = []\n",
    "# terrorist_c = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     # Scores for each item\n",
    "#     love = 0\n",
    "#     charming = 0\n",
    "#     proud = 0\n",
    "#     safe = 0\n",
    "#     resolvable = 0\n",
    "#     prepared = 0\n",
    "#     reach = 0\n",
    "#     backed = 0\n",
    "#     shy = 0\n",
    "#     stutter = 0\n",
    "#     depriving = 0\n",
    "#     ungrateful = 0\n",
    "#     repulse = 0\n",
    "#     cruelness = 0\n",
    "#     slavery = 0\n",
    "#     terrorist = 0\n",
    "    \n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 2:\n",
    "#             love += 1\n",
    "#         if row[\"charming\"] >= 2:\n",
    "#             charming += 1\n",
    "#         if row[\"proud\"] >= 1 and row[\"proud\"] <= 3:\n",
    "#             proud += 1\n",
    "#         if row[\"safe\"] >= 1 and row[\"safe\"] <= 3:\n",
    "#             safe += 1\n",
    "#         if row[\"resolvable\"] >= 0 and row[\"resolvable\"] <= 2:\n",
    "#             resolvable += 1\n",
    "#         if row[\"prepared\"] >= 0 and row[\"prepared\"] <= 2:\n",
    "#             prepared += 1\n",
    "#         if row[\"reach\"] >= -1 and row[\"reach\"] <= 1:\n",
    "#             reach += 1\n",
    "#         if row[\"backed\"] >= -1 and row[\"backed\"] <= 1:\n",
    "#             backed += 1\n",
    "#         if row[\"shy\"] >= -2 and row[\"shy\"] <= 0:\n",
    "#             shy += 1\n",
    "#         if row[\"stutter\"] >= -2 and row[\"stutter\"] <= 0:\n",
    "#             stutter += 1\n",
    "#         if row[\"depriving\"] <= -1 and row[\"depriving\"] >= -3:\n",
    "#             depriving += 1\n",
    "#         if row[\"ungrateful\"] <= -1 and row[\"ungrateful\"] >= -3:\n",
    "#             ungrateful += 1\n",
    "#         if row[\"cruelness\"] <= -2:\n",
    "#             cruelness += 1\n",
    "#         if row[\"repulse\"] <= -2:\n",
    "#             repulse += 1\n",
    "#         if row[\"slavery\"] <= -3:\n",
    "#             slavery += 1\n",
    "#         if row[\"terrorist\"] <= -3:\n",
    "#             terrorist += 1\n",
    "# #         print(counter)\n",
    "# #         if counter / 16 >= 0.8:\n",
    "# #             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "#     print(\"love: \", love)\n",
    "#     love_c.append(love / len(dataframe))\n",
    "#     print(\"charming: \", charming)\n",
    "#     charming_c.append(charming / len(dataframe))\n",
    "#     print(\"proud: \", proud)\n",
    "#     proud_c.append(proud / len(dataframe))\n",
    "#     print(\"safe: \", safe)\n",
    "#     safe_c.append(safe / len(dataframe))\n",
    "#     print(\"resolvable: \", resolvable)\n",
    "#     resolvable_c.append(resolvable / len(dataframe))\n",
    "#     print(\"prepared: \", prepared)\n",
    "#     prepared_c.append(prepared / len(dataframe))\n",
    "#     print(\"reach: \", reach)\n",
    "#     reach_c.append(reach / len(dataframe))\n",
    "#     print(\"backed: \", backed)\n",
    "#     backed_c.append(backed / len(dataframe))\n",
    "#     print(\"shy: \", shy)\n",
    "#     shy_c.append(shy / len(dataframe))\n",
    "#     print(\"stutter: \", stutter)\n",
    "#     stutter_c.append(stutter / len(dataframe))\n",
    "#     print(\"depriving: \", depriving)\n",
    "#     depriving_c.append(depriving / len(dataframe))\n",
    "#     print(\"ungrateful: \", ungrateful)\n",
    "#     ungrateful_c.append(ungrateful / len(dataframe))\n",
    "#     print(\"cruelness: \", cruelness)\n",
    "#     cruelness_c.append(cruelness / len(dataframe))\n",
    "#     print(\"repulse: \", repulse)\n",
    "#     repulse_c.append(repulse / len(dataframe))\n",
    "#     print(\"slavery: \", slavery)\n",
    "#     slavery_c.append(slavery / len(dataframe))\n",
    "#     print(\"terrorist: \", terrorist)\n",
    "#     terrorist_c.append(terrorist / len(dataframe))\n",
    "    \n",
    "# print(\"love: \", sum(love_c) / len(love_c))\n",
    "# print(\"charming: \", sum(charming_c) / len(charming_c))\n",
    "# print(\"proud: \", sum(proud_c) / len(proud_c))\n",
    "# print(\"safe: \", sum(safe_c) / len(safe_c))\n",
    "# print(\"resolvable: \", sum(resolvable_c) / len(resolvable_c))\n",
    "# print(\"prepared: \", sum(prepared_c) / len(prepared_c))\n",
    "# print(\"reach: \", sum(reach_c) / len(reach_c))\n",
    "# print(\"backed: \", sum(backed_c) / len(backed_c))\n",
    "# print(\"shy: \", sum(shy_c) / len(shy_c))\n",
    "# print(\"stutter: \", sum(stutter_c) / len(stutter_c))\n",
    "# print(\"depriving: \", sum(depriving_c) / len(depriving_c))\n",
    "# print(\"ungrateful: \", sum(ungrateful_c) / len(ungrateful_c))\n",
    "# print(\"cruelness: \", sum(cruelness_c) / len(cruelness_c))\n",
    "# print(\"repulse: \", sum(repulse_c) / len(repulse_c))\n",
    "# print(\"slavery: \", sum(slavery_c) / len(slavery_c))\n",
    "# print(\"terrorist: \", sum(terrorist_c) / len(terrorist_c))\n",
    "\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aefe776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On average, how many of the 10 golden items did participants provide within +/- 2 rating for? \n",
    "\n",
    "# how_many_people_correct = []\n",
    "# love_c = []\n",
    "# charming_c = []\n",
    "# proud_c = []\n",
    "# safe_c = []\n",
    "# resolvable_c = []\n",
    "# prepared_c = []\n",
    "# reach_c = []\n",
    "# backed_c = []\n",
    "# shy_c = []\n",
    "# stutter_c = []\n",
    "# depriving_c = []\n",
    "# ungrateful_c = []\n",
    "# repulse_c = []\n",
    "# cruelness_c = []\n",
    "# slavery_c = []\n",
    "# terrorist_c = []\n",
    "\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     # Scores for each item\n",
    "#     love = 0\n",
    "#     charming = 0\n",
    "#     proud = 0\n",
    "#     safe = 0\n",
    "#     resolvable = 0\n",
    "#     prepared = 0\n",
    "#     reach = 0\n",
    "#     backed = 0\n",
    "#     shy = 0\n",
    "#     stutter = 0\n",
    "#     depriving = 0\n",
    "#     ungrateful = 0\n",
    "#     repulse = 0\n",
    "#     cruelness = 0\n",
    "#     slavery = 0\n",
    "#     terrorist = 0\n",
    "    \n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 1:\n",
    "#             love += 1\n",
    "#         if row[\"charming\"] >= 1:\n",
    "#             charming += 1\n",
    "#         if row[\"proud\"] >= 0:\n",
    "#             proud += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             safe += 1\n",
    "#         if row[\"resolvable\"] >= -1 and row[\"resolvable\"] <= 3:\n",
    "#             resolvable += 1\n",
    "#         if row[\"prepared\"] >= -1 and row[\"prepared\"] <= 3:\n",
    "#             prepared += 1\n",
    "#         if row[\"reach\"] >= -2 and row[\"reach\"] <= 2:\n",
    "#             reach += 1\n",
    "#         if row[\"backed\"] >= -2 and row[\"backed\"] <= 2:\n",
    "#             backed += 1\n",
    "#         if row[\"shy\"] >= -3 and row[\"shy\"] <= 1:\n",
    "#             shy += 1\n",
    "#         if row[\"stutter\"] >= -3 and row[\"stutter\"] <= 1:\n",
    "#             stutter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             depriving += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             ungrateful += 1\n",
    "#         if row[\"cruelness\"] <= -1:\n",
    "#             cruelness += 1\n",
    "#         if row[\"repulse\"] <= -1:\n",
    "#             repulse += 1\n",
    "#         if row[\"slavery\"] <= -2:\n",
    "#             slavery += 1\n",
    "#         if row[\"terrorist\"] <= -2:\n",
    "#             terrorist += 1\n",
    "# #         print(counter)\n",
    "# #         if counter / 16 >= 0.8:\n",
    "# #             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "# #     print(\"counter_people: \", counter_people)\n",
    "# #     how_many_people_correct.append(counter_people)\n",
    "\n",
    "#     print(\"love: \", love)\n",
    "#     love_c.append(love / len(dataframe))\n",
    "#     print(\"charming: \", charming)\n",
    "#     charming_c.append(charming / len(dataframe))\n",
    "#     print(\"proud: \", proud)\n",
    "#     proud_c.append(proud / len(dataframe))\n",
    "#     print(\"safe: \", safe)\n",
    "#     safe_c.append(safe / len(dataframe))\n",
    "#     print(\"resolvable: \", resolvable)\n",
    "#     resolvable_c.append(resolvable / len(dataframe))\n",
    "#     print(\"prepared: \", prepared)\n",
    "#     prepared_c.append(prepared / len(dataframe))\n",
    "#     print(\"reach: \", reach)\n",
    "#     reach_c.append(reach / len(dataframe))\n",
    "#     print(\"backed: \", backed)\n",
    "#     backed_c.append(backed / len(dataframe))\n",
    "#     print(\"shy: \", shy)\n",
    "#     shy_c.append(shy / len(dataframe))\n",
    "#     print(\"stutter: \", stutter)\n",
    "#     stutter_c.append(stutter / len(dataframe))\n",
    "#     print(\"depriving: \", depriving)\n",
    "#     depriving_c.append(depriving / len(dataframe))\n",
    "#     print(\"ungrateful: \", ungrateful)\n",
    "#     ungrateful_c.append(ungrateful / len(dataframe))\n",
    "#     print(\"cruelness: \", cruelness)\n",
    "#     cruelness_c.append(cruelness / len(dataframe))\n",
    "#     print(\"repulse: \", repulse)\n",
    "#     repulse_c.append(repulse / len(dataframe))\n",
    "#     print(\"slavery: \", slavery)\n",
    "#     slavery_c.append(slavery / len(dataframe))\n",
    "#     print(\"terrorist: \", terrorist)\n",
    "#     terrorist_c.append(terrorist / len(dataframe))\n",
    "    \n",
    "# print(\"love: \", sum(love_c) / len(love_c))\n",
    "# print(\"charming: \", sum(charming_c) / len(charming_c))\n",
    "# print(\"proud: \", sum(proud_c) / len(proud_c))\n",
    "# print(\"safe: \", sum(safe_c) / len(safe_c))\n",
    "# print(\"resolvable: \", sum(resolvable_c) / len(resolvable_c))\n",
    "# print(\"prepared: \", sum(prepared_c) / len(prepared_c))\n",
    "# print(\"reach: \", sum(reach_c) / len(reach_c))\n",
    "# print(\"backed: \", sum(backed_c) / len(backed_c))\n",
    "# print(\"shy: \", sum(shy_c) / len(shy_c))\n",
    "# print(\"stutter: \", sum(stutter_c) / len(stutter_c))\n",
    "# print(\"depriving: \", sum(depriving_c) / len(depriving_c))\n",
    "# print(\"ungrateful: \", sum(ungrateful_c) / len(ungrateful_c))\n",
    "# print(\"cruelness: \", sum(cruelness_c) / len(cruelness_c))\n",
    "# print(\"repulse: \", sum(repulse_c) / len(repulse_c))\n",
    "# print(\"slavery: \", sum(slavery_c) / len(slavery_c))\n",
    "# print(\"terrorist: \", sum(terrorist_c) / len(terrorist_c))\n",
    "\n",
    "\n",
    "    \n",
    "# # print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# # print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44dae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba271da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d731fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If a golden item was -1, then count as “correct” if they were on the neutral or negative valence side regardless of 0, -1, -2, -3, or -4.\n",
    "# # Same for positive.\n",
    "\n",
    "# how_many_people_correct = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "#     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "# # titanic[titanic[\"Age\"] > 35]\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "#     dataframe = dataframe[dataframe[\"love\"] >= 0] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 0)] # 3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0)] # 2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= 0)] # 1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= 0)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "#     dataframe = dataframe.loc[(dataframe[\"shy\"] <= 0)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"stutter\"] <= 0)] # -1\n",
    "#     dataframe = dataframe.loc[(dataframe[\"depriving\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "#     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= 0)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= 0)] # -3\n",
    "#     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= 0)] # -4\n",
    "#     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= 0)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "#     print(len(dataframe))\n",
    "#     how_many_people_correct.append(len(dataframe))\n",
    "    \n",
    "# print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "137f7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Repeat as above but for 80%. \n",
    "\n",
    "# how_many_people_correct = []\n",
    "# for key in dict_of_dfs.keys():\n",
    "# #     print(\"Change below\")\n",
    "#     dataframe = dict_of_dfs[key]\n",
    "#     print(len(dataframe))\n",
    "\n",
    "#     dataframe = dataframe.loc[:,~dataframe.columns.duplicated()].copy() # Words may be duplicated...\n",
    "    \n",
    "#     counter_people = 0\n",
    "#     for index, row in dataframe.iterrows(): # Row is the particpant\n",
    "#         # Give a point if they get the ideal solution\n",
    "#         counter = 0\n",
    "#         if row[\"love\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"charming\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"proud\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"safe\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"resolvable\"] >= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"prepared\"] >= 0:\n",
    "#             counter += 1\n",
    "# #         if row[\"reach\"] == 0:\n",
    "# #             counter += 1\n",
    "# #         if row[\"backed\"] == 0:\n",
    "# #             counter += 1\n",
    "#         if row[\"shy\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"stutter\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"depriving\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"ungrateful\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"cruelness\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"repulse\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"slavery\"] <= 0:\n",
    "#             counter += 1\n",
    "#         if row[\"terrorist\"] <= 0:\n",
    "#             counter += 1\n",
    "# #         print(counter)\n",
    "#         if counter / 16 >= 0.8:\n",
    "#             counter_people += 1\n",
    "    \n",
    "            \n",
    "    \n",
    "# #     dataframe = dataframe[dataframe[\"love\"] >= 1] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"charming\"] >= 1)] # 3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"proud\"] >= 0) & (dataframe[\"proud\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"safe\"] >= 0) & (dataframe[\"safe\"] <= 4)] # 2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"resolvable\"] >= -1) & (dataframe[\"resolvable\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"prepared\"] >= -1) & (dataframe[\"prepared\"] <= 3)] # 1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"reach\"] >= -2) & (dataframe[\"reach\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"backed\"] >= -2) & (dataframe[\"backed\"] <= 2)] # 0\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"shy\"] >= -3) & (dataframe[\"shy\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"stutter\"] >= -3) & (dataframe[\"stutter\"] <= 1)] # -1\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"depriving\"] >= -4) & (dataframe[\"depriving\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"ungrateful\"] >= -4) & (dataframe[\"ungrateful\"] <= 0)] # -2\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"cruelness\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"repulse\"] <= -1)] # -3\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"slavery\"] <= -2)] # -4\n",
    "# #     dataframe = dataframe.loc[(dataframe[\"terrorist\"] <= -2)] # -4\n",
    "\n",
    "    \n",
    "# #     dict_of_dfs[key] = dataframe\n",
    "#     print(\"counter_people: \", counter_people)\n",
    "#     how_many_people_correct.append(counter_people)\n",
    "    \n",
    "# print(sum(how_many_people_correct) / len(how_many_people_correct))\n",
    "# print(min(how_many_people_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fca6d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(non_excluded) # # of non-excluded participants\n",
    "# print(all_correct) # average % of golden items correct for participants who saw this list\n",
    "# print(all_correct_1) # ave % of golden items within +/- 1 unit\n",
    "# print(all_correct_2) # ave % of golden items within +/- 2 units\n",
    "# print(all_correct_valence) # ave % of NON-neutral golden items in correct valence\n",
    "# print(eighty_correct) # # of participants who got >80% of golden items correct\n",
    "# print(eighty_correct_1) # # of participants who got >80% of golden items within +/- 1 unit\n",
    "# print(eighty_correct_2) # # of participants who got > 80% of golden items within +/- 2 units\n",
    "# print(participants) # # of participants who got NON-neutral golden items in correct valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bab789a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_spread = pd.DataFrame()\n",
    "# sample_spread['# of non-excluded participants'] = pd.Series(non_excluded)\n",
    "# # sample_spread.assign(\"# of non-excluded participants\"=non_excluded)\n",
    "# sample_spread['average % of golden items correct for participants who saw this list'] = pd.Series(all_correct)\n",
    "# sample_spread['ave % of golden items within +/- 1 unit'] = pd.Series(all_correct_1)\n",
    "# sample_spread['ave % of golden items within +/- 2 units'] = pd.Series(all_correct_2)\n",
    "# sample_spread['ave % of NON-neutral golden items in correct valence'] = pd.Series(all_correct_valence)\n",
    "# sample_spread['# of participants who got >80% of golden items correct'] = pd.Series(eighty_correct)\n",
    "# sample_spread['# of participants who got >80% of golden items within +/- 1 unit'] = pd.Series(eighty_correct_1)\n",
    "# sample_spread['# of participants who got > 80% of golden items within +/- 2 units'] = pd.Series(eighty_correct_2)\n",
    "# sample_spread['# of participants who got NON-neutral golden items in correct valence'] = pd.Series(participants)\n",
    "\n",
    "# sample_spread\n",
    "# sample_spread.to_csv('sample_spread.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716f359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
